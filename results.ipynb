{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import operator\n",
    "import itertools \n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir=\"./datasets/\"\n",
    "datasets=[\n",
    "    \"airport\",\n",
    "    \"atom\",\n",
    "    \"CLASSIFICATION\",\n",
    "    \"flights\",\n",
    "    \"food\",\n",
    "    \"Hospital\",\n",
    "    \"inspection\",\n",
    "    \"ncvoter\",\n",
    "    \"SPStock\",\n",
    "    \"tax500k\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "JARDir=\"./algorithmJARs/\"\n",
    "algorithms=[\n",
    "    \"Hydra\",\n",
    "    \"DCFinder\",\n",
    "    \"ADCMiner\",\n",
    "    \"FastADC\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self,file,**args):\n",
    "        self.columns=pd.read_csv(file,nrows=0).columns\n",
    "        self.header=[re.match(r'([^\\(\\)]*)(?:\\(| )([^\\(\\)]*)\\)?',col) for col in self.columns]\n",
    "        self.names=[match[1] for match in self.header]\n",
    "        typeMap={'String':str,'Integer':float,'Double':float,'int':float,'str':str,'float':float}\n",
    "        self.types=[typeMap[match[2]] for match in self.header]\n",
    "        \n",
    "        self.df=pd.read_csv(file,dtype={col:type for col,type in zip(self.columns,self.types)},**args)\n",
    "        \n",
    "    def randRows(self,n):\n",
    "        ids=np.random.randint(0,len(self.df),n)\n",
    "        return self.df.iloc[ids]\n",
    "    def randFields(self,n):\n",
    "        return pd.DataFrame({col:dfs[col].iloc[list(np.random.randint(0,len(dfs),n))].values for dfs in [self.df] for col in dfs.columns})\n",
    "\n",
    "    def buildPLIs(self):\n",
    "        self.PLI= {col:self.df.groupby(by=col).groups for col in self.df}\n",
    "    def shuffle(self):\n",
    "        self.df=self.randFields(len(self.df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DenialConstraintResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Operator:\n",
    "    def __init__(self,func,expFunc) -> None:\n",
    "        self.func=func\n",
    "        self.expFunc=expFunc\n",
    "    def __call__(self,a,b):\n",
    "        return self.func(a,b)\n",
    "    def negate(self):\n",
    "        return Operator(operator.invert(self.func))\n",
    "    def expected(self,c1,c2):\n",
    "        return self.expFunc(c1,c2)\n",
    "    def __repr__(self) -> str:\n",
    "        return self.func.__name__\n",
    "    def __eq__(self, other: object) -> bool:\n",
    "        if isinstance(other, Operator):\n",
    "            return self.func==other.func\n",
    "        return False\n",
    "    def __hash__(self):\n",
    "        fields=(self.func)\n",
    "        hash_value = hash(fields)\n",
    "        return hash_value\n",
    "\n",
    "def eqExp(l,r):\n",
    "    vals,freqs=np.unique(l.values,return_counts=True)\n",
    "    probs=freqs/len(l)\n",
    "    return np.sum(probs**2)-1/len(l)\n",
    "   \n",
    "\n",
    "eq=Operator(operator.eq,eqExp)\n",
    "\n",
    "def neExp(l,r):\n",
    "    vals,freqs=np.unique(l.values,return_counts=True)\n",
    "    probs=freqs/len(l)\n",
    "    return 1-np.sum(probs**2)\n",
    "ne=Operator(operator.ne,neExp)\n",
    "\n",
    "def geExp(l,r):\n",
    "    vals,freqs=np.unique(l.values,return_counts=True)\n",
    "    probs=freqs/len(l)\n",
    "    cumProbs=np.cumsum(probs)\n",
    "    return np.sum(probs*(1-cumProbs+probs))-1/len(l)\n",
    "ge=Operator(operator.ge,geExp)\n",
    "\n",
    "def leExp(l,r):\n",
    "    vals,freqs=np.unique(l.values,return_counts=True)\n",
    "    probs=freqs/len(l)\n",
    "    cumProbs=np.cumsum(probs)\n",
    "    return np.sum(probs*(cumProbs))-1/len(l)\n",
    "le=Operator(operator.le,leExp)\n",
    "\n",
    "def gtExp(l,r):\n",
    "    vals,freqs=np.unique(l.values,return_counts=True)\n",
    "    probs=freqs/len(l)\n",
    "    cumProbs=np.cumsum(probs)\n",
    "    return np.sum(probs*(1-cumProbs))\n",
    "gt=Operator(operator.gt,gtExp)\n",
    "\n",
    "def ltExp(l,r):\n",
    "    vals,freqs=np.unique(l.values,return_counts=True)\n",
    "    probs=freqs/len(l)\n",
    "    cumProbs=np.cumsum(probs)\n",
    "    return np.sum(probs*(cumProbs-probs))\n",
    "lt=Operator(operator.lt,ltExp)\n",
    "operatorMap={\n",
    "    \"EQUAL\":eq,\n",
    "    \"UNEQUAL\":ne,\n",
    "    \"LESS_EQUAL\":le,\n",
    "    \"GREATER_EQUAL\":ge,\n",
    "    \"LESS\":lt,\n",
    "    \"GREATER\":gt\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "class Predicate:\n",
    "    def __init__(self,l:str,op:Operator,r:str) -> None:\n",
    "        self.l=l\n",
    "        self.r=r\n",
    "        self.op=op\n",
    "        self.exp=None\n",
    "    def eval(self,df,t0,t1):\n",
    "        return self.op(t0[self.l],t1[self.r])\n",
    "    def expected(self,df):\n",
    "        if self.exp is None:\n",
    "            self.exp=self.op.expected(df.df[self.l],None)\n",
    "        return self.exp\n",
    "            \n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return '\"'+self.l +'\" '+self.op.__repr__()+' \"'+self.r+'\"'\n",
    "    def __hash__(self):\n",
    "        fields=(self.l,self.r)\n",
    "        hash_value = hash(fields)\n",
    "        return hash_value\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, Predicate):\n",
    "            sFields=(self.l,self.op,self.r)\n",
    "            oFields=(other.l,other.op,other.r)\n",
    "            return sFields==oFields\n",
    "        return False\n",
    "\n",
    "\n",
    "class DenialConstraint:\n",
    "    def __init__(self,preds) -> None:\n",
    "        self.preds=preds\n",
    "    def eval(self,df,t0,t1):\n",
    "        return sum([pred.eval(df,t0,t1) for pred in self.preds])\n",
    "    def coverage(self,df,t0s,t1s):\n",
    "        pos,neg=0,0\n",
    "        num=self.eval(df,t0s,t1s)\n",
    "        dclen=len(self.preds)\n",
    "        pos=(num==dclen).sum()\n",
    "        neg=(num<dclen).sum()\n",
    "\n",
    "                \n",
    "        return neg/(pos+neg)\n",
    "    def sampleCoverage(self,df,n=None):\n",
    "        nn=len(df.df)\n",
    "        if n is None:\n",
    "            n=nn**2\n",
    "        t0s = np.random.randint(0,len(df.df),n)\n",
    "        t1s = np.random.randint(0,len(df.df),n)\n",
    "        t1s=(t1s+(t1s==t0s)*np.random.randint(1,len(df.df),n))%len(df.df)\n",
    "        return self.coverage(df,t0s,t1s)\n",
    "    def expCoverage(self,df):\n",
    "        return 1-np.prod([pred.expected(df) for pred in self.preds])\n",
    "    def __repr__(self) -> str:\n",
    "        return \"![\"+\" & \".join([pred.__repr__() for pred in self.preds])+\"]\"\n",
    "\n",
    "\n",
    "class DenialConstraintSet:\n",
    "    def __init__(self,path,dataset,algorithm) -> None:        \n",
    "        self.predicates={}\n",
    "        opmap={\"==\":eq,\"<>\":ne,\">=\":ge,\"<=\":le,\">\":gt,\"<\":lt}\n",
    "        def getPred(c1,op,c2):\n",
    "            if (c1,c2,op) not in self.predicates:\n",
    "                self.predicates[(c1,c2,op)]=Predicate(c1,opmap[op],c2)\n",
    "            return self.predicates[(c1,c2,op)]\n",
    "        \n",
    "        self.DCs=[]\n",
    "        \n",
    "        with open(path) as f:\n",
    "            for line in f:\n",
    "                line=line.strip()[2:-1] #strip !(...)\n",
    "                preds=line.split('^')\n",
    "                regex=r't0\\.'+dataset+'\\.csv\\.([^=><]*)(==|<>|>=|<=|>|<)t1\\.'+dataset+'\\.csv\\.([^=><]*)'\n",
    "                if algorithm in ['ADCMiner','FastADC']:\n",
    "                    regex=r't0\\.([^=><]*) (==|<>|>=|<=|>|<) t1\\.([^=><]*)'\n",
    "                preds = [getPred(*re.match(regex,pred).groups()) for pred in preds]\n",
    "                self.DCs.append(DenialConstraint(preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discover DCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN: Hydra_tax500k_0.00\n",
      "12:19:13.576 [main] INFO  d.h.n.dc.algorithms.hybrid.Hydra - Building approximate evidence set...\n",
      "12:19:13.740 [main] INFO  d.h.n.dc.algorithms.hybrid.Hydra - Estimation size systematic sampling:293\n",
      "12:19:13.810 [main] INFO  d.h.n.d.e.b.s.ColumnAwareEvidenceSetBuilder - Sampling column LName(String)\n",
      "12:19:13.881 [main] INFO  d.h.n.d.e.b.s.ColumnAwareEvidenceSetBuilder - Sampling column Gender(String)\n",
      "12:19:13.882 [main] INFO  d.h.n.d.e.b.s.ColumnAwareEvidenceSetBuilder - Sampling column AreaCode(String)\n",
      "12:19:13.883 [main] INFO  d.h.n.d.e.b.s.ColumnAwareEvidenceSetBuilder - Sampling column Phone(String)\n",
      "12:19:13.884 [main] INFO  d.h.n.d.e.b.s.ColumnAwareEvidenceSetBuilder - Sampling column City(String)\n",
      "12:19:13.885 [main] INFO  d.h.n.d.e.b.s.ColumnAwareEvidenceSetBuilder - Sampling column State(String)\n",
      "12:19:13.886 [main] INFO  d.h.n.d.e.b.s.ColumnAwareEvidenceSetBuilder - Sampling column Zip(String)\n",
      "12:19:13.888 [main] INFO  d.h.n.d.e.b.s.ColumnAwareEvidenceSetBuilder - Sampling column MaritalStatus(String)\n",
      "12:19:13.888 [main] INFO  d.h.n.d.e.b.s.ColumnAwareEvidenceSetBuilder - Sampling column HasChild(String)\n",
      "12:19:13.889 [main] INFO  d.h.n.d.e.b.s.ColumnAwareEvidenceSetBuilder - Sampling column Rate(Double)\n",
      "12:19:13.894 [main] INFO  d.h.n.d.e.b.s.ColumnAwareEvidenceSetBuilder - Sampling column SingleExemp(Integer)\n",
      "12:19:13.895 [main] INFO  d.h.n.d.e.b.s.ColumnAwareEvidenceSetBuilder - Sampling column MarriedExemp(Integer)\n",
      "12:19:13.896 [main] INFO  d.h.n.d.e.b.s.ColumnAwareEvidenceSetBuilder - Sampling column ChildExemp(Integer)\n",
      "12:19:13.910 [main] INFO  d.h.n.dc.algorithms.hybrid.Hydra - Evidence set size deterministic sampler: 443\n",
      "12:19:13.954 [main] INFO  d.h.n.d.c.PrefixMinimalCoverSearch - Evidence Set size: 443\n",
      "12:19:14.038 [main] INFO  d.h.n.d.c.PrefixMinimalCoverSearch - Building new bitsets..\n",
      "12:19:14.038 [main] INFO  d.h.n.d.c.PrefixMinimalCoverSearch - Sorting new bitsets..\n",
      "12:19:14.050 [main] INFO  d.h.n.d.c.PrefixMinimalCoverSearch - starting inverting size 443\n",
      "12:19:14.149 [main] INFO  d.h.n.d.c.PrefixMinimalCoverSearch - Finished sorting neg 2. list size:443\n",
      "12:19:14.274 [main] INFO  d.h.n.d.c.PrefixMinimalCoverSearch - 1302\n",
      "12:19:14.274 [main] INFO  d.h.n.dc.algorithms.hybrid.Hydra - DC count approx:1302\n",
      "12:19:14.408 [main] INFO  d.h.n.d.d.DenialConstraintSet - Sym size created 1302\n",
      "12:19:14.466 [main] INFO  d.h.n.dc.algorithms.hybrid.Hydra - DC count approx after minimize:679\n",
      "12:19:14.489 [main] INFO  d.h.n.d.a.hybrid.ResultCompletion - Checking 679 DCs.\n",
      "12:19:14.490 [main] INFO  d.h.n.d.a.hybrid.ResultCompletion - Building selectivity estimation\n",
      "12:19:14.650 [main] INFO  d.h.n.d.a.hybrid.ResultCompletion - Grouping DCs..\n",
      "12:19:14.697 [main] INFO  d.h.n.d.a.hybrid.ResultCompletion - Calculating partitions..\n",
      "12:19:14.727 [main] INFO  de.hpi.naumann.dc.input.Input - rebuild: 1\n",
      "12:19:15.009 [main] INFO  d.h.n.d.c.PrefixMinimalCoverSearch - Evidence Set size: 467\n",
      "12:19:15.010 [main] INFO  d.h.n.d.c.PrefixMinimalCoverSearch - Building new bitsets..\n",
      "12:19:15.011 [main] INFO  d.h.n.d.c.PrefixMinimalCoverSearch - Sorting new bitsets..\n",
      "12:19:15.011 [main] INFO  d.h.n.d.c.PrefixMinimalCoverSearch - starting inverting size 467\n",
      "12:19:15.043 [main] INFO  d.h.n.d.c.PrefixMinimalCoverSearch - Finished sorting neg 2. list size:467\n",
      "12:19:15.092 [main] INFO  d.h.n.d.c.PrefixMinimalCoverSearch - 1105\n",
      "12:19:15.180 [main] INFO  d.h.n.d.d.DenialConstraintSet - Sym size created 1105\n",
      "\n",
      "Lines written to file successfully!\n",
      "MOVE: Hydra_tax500k_0.00\n",
      "RUN: Hydra_tax500k_0.01\n",
      "12:19:16.342 [main] INFO  d.h.n.dc.algorithms.hybrid.Hydra - Building approximate evidence set...\n",
      "12:19:16.485 [main] INFO  d.h.n.dc.algorithms.hybrid.Hydra - Estimation size systematic sampling:284\n",
      "12:19:16.553 [main] INFO  d.h.n.d.e.b.s.ColumnAwareEvidenceSetBuilder - Sampling column LName(String)\n",
      "12:19:16.657 [main] INFO  d.h.n.d.e.b.s.ColumnAwareEvidenceSetBuilder - Sampling column Gender(String)\n",
      "12:19:16.659 [main] INFO  d.h.n.d.e.b.s.ColumnAwareEvidenceSetBuilder - Sampling column AreaCode(String)\n",
      "12:19:16.661 [main] INFO  d.h.n.d.e.b.s.ColumnAwareEvidenceSetBuilder - Sampling column Phone(String)\n",
      "12:19:16.663 [main] INFO  d.h.n.d.e.b.s.ColumnAwareEvidenceSetBuilder - Sampling column City(String)\n",
      "12:19:16.664 [main] INFO  d.h.n.d.e.b.s.ColumnAwareEvidenceSetBuilder - Sampling column State(String)\n",
      "12:19:16.665 [main] INFO  d.h.n.d.e.b.s.ColumnAwareEvidenceSetBuilder - Sampling column Zip(String)\n",
      "12:19:16.666 [main] INFO  d.h.n.d.e.b.s.ColumnAwareEvidenceSetBuilder - Sampling column MaritalStatus(String)\n",
      "12:19:16.667 [main] INFO  d.h.n.d.e.b.s.ColumnAwareEvidenceSetBuilder - Sampling column HasChild(String)\n",
      "12:19:16.668 [main] INFO  d.h.n.d.e.b.s.ColumnAwareEvidenceSetBuilder - Sampling column Rate(Double)\n",
      "12:19:16.679 [main] INFO  d.h.n.d.e.b.s.ColumnAwareEvidenceSetBuilder - Sampling column SingleExemp(Integer)\n",
      "12:19:16.681 [main] INFO  d.h.n.d.e.b.s.ColumnAwareEvidenceSetBuilder - Sampling column MarriedExemp(Integer)\n",
      "12:19:16.682 [main] INFO  d.h.n.d.e.b.s.ColumnAwareEvidenceSetBuilder - Sampling column ChildExemp(Integer)\n",
      "12:19:16.705 [main] INFO  d.h.n.dc.algorithms.hybrid.Hydra - Evidence set size deterministic sampler: 443\n",
      "12:19:16.762 [main] INFO  d.h.n.d.c.PrefixMinimalCoverSearch - Evidence Set size: 443\n",
      "12:19:16.884 [main] INFO  d.h.n.d.c.PrefixMinimalCoverSearch - Building new bitsets..\n",
      "12:19:16.885 [main] INFO  d.h.n.d.c.PrefixMinimalCoverSearch - Sorting new bitsets..\n",
      "12:19:16.914 [main] INFO  d.h.n.d.c.PrefixMinimalCoverSearch - starting inverting size 443\n",
      "12:19:17.030 [main] INFO  d.h.n.d.c.PrefixMinimalCoverSearch - Finished sorting neg 2. list size:443\n",
      "12:19:17.203 [main] INFO  d.h.n.d.c.PrefixMinimalCoverSearch - 1307\n",
      "12:19:17.204 [main] INFO  d.h.n.dc.algorithms.hybrid.Hydra - DC count approx:1307\n",
      "12:19:17.377 [main] INFO  d.h.n.d.d.DenialConstraintSet - Sym size created 1307\n",
      "12:19:17.471 [main] INFO  d.h.n.dc.algorithms.hybrid.Hydra - DC count approx after minimize:690\n",
      "12:19:17.490 [main] INFO  d.h.n.d.a.hybrid.ResultCompletion - Checking 690 DCs.\n",
      "12:19:17.490 [main] INFO  d.h.n.d.a.hybrid.ResultCompletion - Building selectivity estimation\n",
      "12:19:17.628 [main] INFO  d.h.n.d.a.hybrid.ResultCompletion - Grouping DCs..\n",
      "12:19:17.666 [main] INFO  d.h.n.d.a.hybrid.ResultCompletion - Calculating partitions..\n",
      "12:19:17.701 [main] INFO  de.hpi.naumann.dc.input.Input - rebuild: 2\n",
      "12:19:17.998 [main] INFO  d.h.n.d.c.PrefixMinimalCoverSearch - Evidence Set size: 467\n",
      "12:19:18.000 [main] INFO  d.h.n.d.c.PrefixMinimalCoverSearch - Building new bitsets..\n",
      "12:19:18.000 [main] INFO  d.h.n.d.c.PrefixMinimalCoverSearch - Sorting new bitsets..\n",
      "12:19:18.002 [main] INFO  d.h.n.d.c.PrefixMinimalCoverSearch - starting inverting size 467\n",
      "12:19:18.055 [main] INFO  d.h.n.d.c.PrefixMinimalCoverSearch - Finished sorting neg 2. list size:467\n",
      "12:19:18.115 [main] INFO  d.h.n.d.c.PrefixMinimalCoverSearch - 1105\n",
      "12:19:18.198 [main] INFO  d.h.n.d.d.DenialConstraintSet - Sym size created 1105\n",
      "\n",
      "Lines written to file successfully!\n",
      "MOVE: Hydra_tax500k_0.01\n",
      "RUN: DCFinder_tax500k_0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[main] INFO de.metanome.algorithms.dcfinder.input.Input - Time to build plis: 267\n",
      "[main] INFO de.metanome.algorithms.dcfinder.DCFinder - Error threshold: 0.0.\n",
      "[main] INFO de.metanome.algorithms.dcfinder.DCFinder - Discovering DCs with at most 0 violating tuple pairs.\n",
      "[main] INFO de.metanome.algorithms.dcfinder.evidenceset.builders.SplitReconstructEvidenceSetBuilder - First level chunks: 1\n",
      "[main] INFO de.metanome.algorithms.dcfinder.evidenceset.builders.SplitReconstructEvidenceSetBuilder - Available processors: 12\n",
      "[main] INFO de.metanome.algorithms.dcfinder.evidenceset.builders.SplitReconstructEvidenceSetBuilder - Building the Evidence Set...\n",
      "[main] INFO de.metanome.algorithms.dcfinder.setcover.partial.MinimalCoverSearch - Finding Minimal Covers for the Evidence Set...\n",
      "[main] INFO de.metanome.algorithms.dcfinder.setcover.partial.MinimalCoverSearch - Building denial constraints...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lines written to file successfully!\n",
      "MOVE: DCFinder_tax500k_0.00\n",
      "RUN: DCFinder_tax500k_0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[main] INFO de.metanome.algorithms.dcfinder.input.Input - Time to build plis: 184\n",
      "[main] INFO de.metanome.algorithms.dcfinder.DCFinder - Error threshold: 0.01.\n",
      "[main] INFO de.metanome.algorithms.dcfinder.DCFinder - Discovering DCs with at most 99 violating tuple pairs.\n",
      "[main] INFO de.metanome.algorithms.dcfinder.evidenceset.builders.SplitReconstructEvidenceSetBuilder - First level chunks: 1\n",
      "[main] INFO de.metanome.algorithms.dcfinder.evidenceset.builders.SplitReconstructEvidenceSetBuilder - Available processors: 12\n",
      "[main] INFO de.metanome.algorithms.dcfinder.evidenceset.builders.SplitReconstructEvidenceSetBuilder - Building the Evidence Set...\n",
      "[main] INFO de.metanome.algorithms.dcfinder.setcover.partial.MinimalCoverSearch - Finding Minimal Covers for the Evidence Set...\n",
      "[main] INFO de.metanome.algorithms.dcfinder.setcover.partial.MinimalCoverSearch - Building denial constraints...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lines written to file successfully!\n",
      "MOVE: DCFinder_tax500k_0.01\n",
      "RUN: ADCMiner_tax500k_0.00\n",
      "INPUT FILE: ./datasets/tax500k.csv\n",
      "predicate space size: 42\n",
      "[Common] Pre-process time: 97ms\n",
      " [Evi t0] 2024-02-05 12:19:22\n",
      "  [Evi Builder] First level chunks: 1\n",
      " [Evi Builder] Building the Evidence Set...\n",
      "Error threshold: 0.0\n",
      "Discovering DCs with at most 0 violating tuple pairs\n",
      " [Evi Builder] evidence set size: 467\n",
      " [Evi Builder] evidence count: 9900\n",
      "[Evi Builder] evidence time: 42ms\n",
      " [ADC t0] 2024-02-05 12:19:22\n",
      " [ADC] Searching min covers...\n",
      "  [ADC] final node size: 0\n",
      " [ADC] Min cover size: 1989\n",
      " [ADC] Total DC size: 1105\n",
      " [ADC] Min DC size : 614\n",
      "[ADC] inversion time: 271ms\n",
      "\n",
      "[ADC] Total computing time: 410 ms\n",
      "\n",
      "Lines written to file successfully!\n",
      "MOVE: ADCMiner_tax500k_0.00\n",
      "RUN: ADCMiner_tax500k_0.01\n",
      "INPUT FILE: ./datasets/tax500k.csv\n",
      "predicate space size: 42\n",
      "[Common] Pre-process time: 93ms\n",
      " [Evi t0] 2024-02-05 12:19:23\n",
      "  [Evi Builder] First level chunks: 1\n",
      " [Evi Builder] Building the Evidence Set...\n",
      "Error threshold: 0.01\n",
      "Discovering DCs with at most 99 violating tuple pairs\n",
      " [Evi Builder] evidence set size: 467\n",
      " [Evi Builder] evidence count: 9900\n",
      "[Evi Builder] evidence time: 42ms\n",
      " [ADC t0] 2024-02-05 12:19:23\n",
      " [ADC] Searching min covers...\n",
      "  [ADC] final node size: 0\n",
      " [ADC] Min cover size: 4693\n",
      " [ADC] Total DC size: 2506\n",
      " [ADC] Min DC size : 1752\n",
      "[ADC] inversion time: 766ms\n",
      "\n",
      "[ADC] Total computing time: 901 ms\n",
      "\n",
      "Lines written to file successfully!\n",
      "MOVE: ADCMiner_tax500k_0.01\n",
      "RUN: FastADC_tax500k_0.00\n",
      "INPUT FILE: ./datasets/tax500k.csv\n",
      "ERROR THRESHOLD: 0.0\n",
      " [Input] # of Tuples: 100\n",
      " [Input] # of Attributes: 13\n",
      " [Predicate] Predicate space size: 42\n",
      "[FastADC] Pre-process time: 124ms\n",
      "  [CLUE] # of bits in clue: 17\n",
      "  [CLUE] task count: 1\n",
      " [Evidence] # of evidences: 467\n",
      " [Evidence] Accumulated evidence count: 9900\n",
      "[FastADC] Evidence time: 47ms\n",
      " [AEI Start] 2024-02-05 12:19:24\n",
      " [AEI] Violate at most 0 tuple pairs\n",
      "  [AEI] Inverting evidences...\n",
      "  [AEI] Min cover size: 1989\n",
      "  [AEI] Total DC size: 1105\n",
      "  [AEI] Min DC size : 614\n",
      "[FastADC] AEI time: 330ms\n",
      "[FastADC] Total computing time: 501 ms\n",
      "\n",
      "\n",
      "Lines written to file successfully!\n",
      "MOVE: FastADC_tax500k_0.00\n",
      "RUN: FastADC_tax500k_0.01\n",
      "INPUT FILE: ./datasets/tax500k.csv\n",
      "ERROR THRESHOLD: 0.01\n",
      " [Input] # of Tuples: 100\n",
      " [Input] # of Attributes: 13\n",
      " [Predicate] Predicate space size: 42\n",
      "[FastADC] Pre-process time: 124ms\n",
      "  [CLUE] # of bits in clue: 17\n",
      "  [CLUE] task count: 1\n",
      " [Evidence] # of evidences: 467\n",
      " [Evidence] Accumulated evidence count: 9900\n",
      "[FastADC] Evidence time: 46ms\n",
      " [AEI Start] 2024-02-05 12:19:25\n",
      " [AEI] Violate at most 99 tuple pairs\n",
      "  [AEI] Inverting evidences...\n",
      "  [AEI] Min cover size: 4693\n",
      "  [AEI] Total DC size: 2506\n",
      "  [AEI] Min DC size : 1752\n",
      "[FastADC] AEI time: 1000ms\n",
      "[FastADC] Total computing time: 1170 ms\n",
      "\n",
      "\n",
      "Lines written to file successfully!\n",
      "MOVE: FastADC_tax500k_0.01\n"
     ]
    }
   ],
   "source": [
    "for dataset in [\"tax500k\"]:\n",
    "    for algorithm in algorithms:\n",
    "        for aprox in [\"0.00\",\"0.01\"]:\n",
    "            print(\"RUN: {}_{}_{}\".format(algorithm,dataset,aprox))\n",
    "            command='java -Xmx8g -cp {} Main {} {} 100'.format(JARDir+algorithm+'.jar',dataDir+dataset+\".csv\",aprox)\n",
    "            result = subprocess.run(command, shell=True)\n",
    "            print(\"MOVE: {}_{}_{}\".format(algorithm,dataset,aprox))\n",
    "            command='mv output.txt results/{}_{}_{}'.format(algorithm,dataset,aprox)\n",
    "            result = subprocess.run(command, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcs=DenialConstraintSet(\"output.txt\",\"Hospital\",\"FastADC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age(Integer)</th>\n",
       "      <th>workclass(String)</th>\n",
       "      <th>fnlwgt(Integer)</th>\n",
       "      <th>education(String)</th>\n",
       "      <th>Marital-status(String)</th>\n",
       "      <th>occupation(String)</th>\n",
       "      <th>relationship(String)</th>\n",
       "      <th>race(String)</th>\n",
       "      <th>sex(String)</th>\n",
       "      <th>Native-country(String)</th>\n",
       "      <th>class(String)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>37</td>\n",
       "      <td>Private</td>\n",
       "      <td>284582</td>\n",
       "      <td>Masters</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>49</td>\n",
       "      <td>Private</td>\n",
       "      <td>160187</td>\n",
       "      <td>9th</td>\n",
       "      <td>Married-spouse-absent</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>Jamaica</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>209642</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>31</td>\n",
       "      <td>Private</td>\n",
       "      <td>45781</td>\n",
       "      <td>Masters</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>42</td>\n",
       "      <td>Private</td>\n",
       "      <td>159449</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age(Integer)  workclass(String)  fnlwgt(Integer) education(String)  \\\n",
       "0            39          State-gov            77516         Bachelors   \n",
       "1            50   Self-emp-not-inc            83311         Bachelors   \n",
       "2            38            Private           215646           HS-grad   \n",
       "3            53            Private           234721              11th   \n",
       "4            28            Private           338409         Bachelors   \n",
       "5            37            Private           284582           Masters   \n",
       "6            49            Private           160187               9th   \n",
       "7            52   Self-emp-not-inc           209642           HS-grad   \n",
       "8            31            Private            45781           Masters   \n",
       "9            42            Private           159449         Bachelors   \n",
       "\n",
       "   Marital-status(String)  occupation(String) relationship(String)  \\\n",
       "0           Never-married        Adm-clerical        Not-in-family   \n",
       "1      Married-civ-spouse     Exec-managerial              Husband   \n",
       "2                Divorced   Handlers-cleaners        Not-in-family   \n",
       "3      Married-civ-spouse   Handlers-cleaners              Husband   \n",
       "4      Married-civ-spouse      Prof-specialty                 Wife   \n",
       "5      Married-civ-spouse     Exec-managerial                 Wife   \n",
       "6   Married-spouse-absent       Other-service        Not-in-family   \n",
       "7      Married-civ-spouse     Exec-managerial              Husband   \n",
       "8           Never-married      Prof-specialty        Not-in-family   \n",
       "9      Married-civ-spouse     Exec-managerial              Husband   \n",
       "\n",
       "  race(String) sex(String) Native-country(String) class(String)  \n",
       "0        White        Male          United-States         <=50K  \n",
       "1        White        Male          United-States         <=50K  \n",
       "2        White        Male          United-States         <=50K  \n",
       "3        Black        Male          United-States         <=50K  \n",
       "4        Black      Female                   Cuba         <=50K  \n",
       "5        White      Female          United-States         <=50K  \n",
       "6        Black      Female                Jamaica         <=50K  \n",
       "7        White        Male          United-States          >50K  \n",
       "8        White      Female          United-States          >50K  \n",
       "9        White        Male          United-States          >50K  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"datasets/adult.csv\")\n",
    "df=df.drop(['capital-gain(Double)','capital-loss(Double)','Hours-per-week(Double)','Education-num(Integer)'],axis=1)\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"adult.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dcs.DCs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds=Dataset(\"datasets/Hospital.csv\")\n",
    "ds.buildPLIs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=10000\n",
    "t0s = ds.randFields(n)\n",
    "t1s = ds.randFields(n)\n",
    "\n",
    "res=[ dc.coverage(ds,t0s,t1s) for dc in dcs.DCs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i,r in enumerate(res) if r<0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[![\"ZIP Code(String)\" eq \"ZIP Code(String)\"],\n",
       " ![\"Condition(String)\" ne \"Condition(String)\" & \"Measure Code(String)\" eq \"Measure Code(String)\"],\n",
       " ![\"Condition(String)\" ne \"Condition(String)\" & \"Measure Name(String)\" eq \"Measure Name(String)\"],\n",
       " ![\"County Name(String)\" eq \"County Name(String)\" & \"Sample(String)\" eq \"Sample(String)\"],\n",
       " ![\"County Name(String)\" eq \"County Name(String)\" & \"State(String)\" ne \"State(String)\"],\n",
       " ![\"StateAvg(String)\" eq \"StateAvg(String)\"],\n",
       " ![\"Measure Name(String)\" eq \"Measure Name(String)\" & \"Sample(String)\" eq \"Sample(String)\"],\n",
       " ![\"County Name(String)\" eq \"County Name(String)\" & \"Measure Name(String)\" eq \"Measure Name(String)\"],\n",
       " ![\"Condition(String)\" eq \"Condition(String)\" & \"County Name(String)\" eq \"County Name(String)\"],\n",
       " ![\"Condition(String)\" eq \"Condition(String)\" & \"Hospital Type(String)\" ne \"Hospital Type(String)\" & \"State(String)\" eq \"State(String)\"],\n",
       " ![\"Hospital Type(String)\" ne \"Hospital Type(String)\" & \"Measure Code(String)\" eq \"Measure Code(String)\"],\n",
       " ![\"Sample(String)\" eq \"Sample(String)\" & \"State(String)\" eq \"State(String)\"],\n",
       " ![\"Hospital Type(String)\" ne \"Hospital Type(String)\" & \"Measure Name(String)\" eq \"Measure Name(String)\"],\n",
       " ![\"Hospital Name(String)\" eq \"Hospital Name(String)\"],\n",
       " ![\"Measure Code(String)\" eq \"Measure Code(String)\" & \"Measure Name(String)\" ne \"Measure Name(String)\"],\n",
       " ![\"Measure Code(String)\" ne \"Measure Code(String)\" & \"Measure Name(String)\" eq \"Measure Name(String)\"],\n",
       " ![\"Phone Number(String)\" eq \"Phone Number(String)\"],\n",
       " ![\"Hospital Type(String)\" ne \"Hospital Type(String)\" & \"Sample(String)\" eq \"Sample(String)\"],\n",
       " ![\"County Name(String)\" eq \"County Name(String)\" & \"Hospital Type(String)\" ne \"Hospital Type(String)\"],\n",
       " ![\"Measure Name(String)\" eq \"Measure Name(String)\" & \"State(String)\" eq \"State(String)\"],\n",
       " ![\"Emergency Service(String)\" ne \"Emergency Service(String)\" & \"Sample(String)\" eq \"Sample(String)\"],\n",
       " ![\"County Name(String)\" eq \"County Name(String)\" & \"Emergency Service(String)\" ne \"Emergency Service(String)\"],\n",
       " ![\"Measure Code(String)\" eq \"Measure Code(String)\" & \"Sample(String)\" eq \"Sample(String)\"],\n",
       " ![\"County Name(String)\" eq \"County Name(String)\" & \"Measure Code(String)\" eq \"Measure Code(String)\"],\n",
       " ![\"Hospital Owner(String)\" eq \"Hospital Owner(String)\" & \"Sample(String)\" eq \"Sample(String)\"],\n",
       " ![\"Hospital Owner(String)\" eq \"Hospital Owner(String)\" & \"Measure Name(String)\" eq \"Measure Name(String)\"],\n",
       " ![\"Condition(String)\" eq \"Condition(String)\" & \"Hospital Owner(String)\" eq \"Hospital Owner(String)\" & \"Hospital Type(String)\" ne \"Hospital Type(String)\"],\n",
       " ![\"Measure Code(String)\" eq \"Measure Code(String)\" & \"State(String)\" eq \"State(String)\"],\n",
       " ![\"Condition(String)\" ne \"Condition(String)\" & \"Emergency Service(String)\" ne \"Emergency Service(String)\" & \"Hospital Type(String)\" ne \"Hospital Type(String)\" & \"State(String)\" ne \"State(String)\"],\n",
       " ![\"Hospital Owner(String)\" eq \"Hospital Owner(String)\" & \"Measure Code(String)\" eq \"Measure Code(String)\"],\n",
       " ![\"Provider Number(String)\" eq \"Provider Number(String)\"],\n",
       " ![\"City(String)\" eq \"City(String)\"],\n",
       " ![\"Emergency Service(String)\" ne \"Emergency Service(String)\" & \"Hospital Owner(String)\" eq \"Hospital Owner(String)\" & \"State(String)\" eq \"State(String)\"],\n",
       " ![\"Hospital Owner(String)\" eq \"Hospital Owner(String)\" & \"Hospital Type(String)\" ne \"Hospital Type(String)\" & \"State(String)\" eq \"State(String)\"]]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcs.DCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9963751279140795"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcs.DCs[8804].expCoverage(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[8804]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04550623851887257"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ltExp(ds.df['capital-loss float'],ds.df['capital-loss float'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "line='¬(t0.adult.csv.Native-country str<>t1.adult.csv.Native-country str^t0.adult.csv.capital-gain float<>t1.adult.csv.capital-gain float^t0.adult.csv.class str==t1.adult.csv.class str^t0.adult.csv.race str==t1.adult.csv.race str)'\n",
    "line=line[2:-1] #strip !(...)\n",
    "preds=line.split('^')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        True\n",
       "1        True\n",
       "2        True\n",
       "3        True\n",
       "4        True\n",
       "         ... \n",
       "32556    True\n",
       "32557    True\n",
       "32558    True\n",
       "32559    True\n",
       "32560    True\n",
       "Name: age int, Length: 32561, dtype: bool"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eq(ds.df['age int'],ds.df['age int'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
