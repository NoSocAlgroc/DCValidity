{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import operator\n",
    "import itertools \n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir=\"./datasets/\"\n",
    "datasets=[\n",
    "    \"adult\",\n",
    "    \"airport\",\n",
    "    \"atom\",\n",
    "    \"CLASSIFICATION\",\n",
    "    \"flights\",\n",
    "    \"food\",\n",
    "    \"Hospital\",\n",
    "    \"inspection\",\n",
    "    \"ncvoter\",\n",
    "    \"SPStock\",\n",
    "    \"tax500k\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "JARDir=\"./algorithmJARs/\"\n",
    "algorithms=[\n",
    "    \"Hydra\",\n",
    "    \"DCFinder\",\n",
    "    \"ADCMiner\",\n",
    "    \"FastADC\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self,file,**args):\n",
    "        self.columns=pd.read_csv(file,nrows=0).columns\n",
    "        self.header=[re.match(r'([^\\(\\)]*)(?:\\(| )([^\\(\\)]*)\\)?',col) for col in self.columns]\n",
    "        self.names=[match[1] for match in self.header]\n",
    "        typeMap={'String':str,'Integer':float,'Double':float,'int':float,'str':str,'float':float}\n",
    "        self.types=[typeMap[match[2]] for match in self.header]\n",
    "        \n",
    "        self.df=pd.read_csv(file,dtype={col:type for col,type in zip(self.columns,self.types)},**args)\n",
    "        \n",
    "    def randRows(self,n):\n",
    "        ids=np.random.randint(0,len(self.df),n)\n",
    "        return self.df.iloc[ids]\n",
    "    def randFields(self,n):\n",
    "        return pd.DataFrame({col:dfs[col].iloc[list(np.random.randint(0,len(dfs),n))].values for dfs in [self.df] for col in dfs.columns})\n",
    "\n",
    "    def buildPLIs(self):\n",
    "        self.PLI= {col:self.df.groupby(by=col).groups for col in self.df}\n",
    "    def shuffle(self):\n",
    "        self.df=self.randFields(len(self.df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DenialConstraintResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Operator:\n",
    "    def __init__(self,func,expFunc) -> None:\n",
    "        self.func=func\n",
    "        self.expFunc=expFunc\n",
    "    def __call__(self,a,b):\n",
    "        return self.func(a,b)\n",
    "    def negate(self):\n",
    "        return Operator(operator.invert(self.func))\n",
    "    def expected(self,c1,c2):\n",
    "        return self.expFunc(c1,c2)\n",
    "    def __repr__(self) -> str:\n",
    "        return self.func.__name__\n",
    "    def __eq__(self, other: object) -> bool:\n",
    "        if isinstance(other, Operator):\n",
    "            return self.func==other.func\n",
    "        return False\n",
    "    def __hash__(self):\n",
    "        fields=(self.func)\n",
    "        hash_value = hash(fields)\n",
    "        return hash_value\n",
    "\n",
    "def eqExp(l,r):\n",
    "    vals,freqs=np.unique(l.values,return_counts=True)\n",
    "    probs=freqs/len(l)\n",
    "    return np.sum(probs**2)-1/len(l)\n",
    "   \n",
    "\n",
    "eq=Operator(operator.eq,eqExp)\n",
    "\n",
    "def neExp(l,r):\n",
    "    vals,freqs=np.unique(l.values,return_counts=True)\n",
    "    probs=freqs/len(l)\n",
    "    return 1-np.sum(probs**2)\n",
    "ne=Operator(operator.ne,neExp)\n",
    "\n",
    "def geExp(l,r):\n",
    "    vals,freqs=np.unique(l.values,return_counts=True)\n",
    "    probs=freqs/len(l)\n",
    "    cumProbs=np.cumsum(probs)\n",
    "    return np.sum(probs*(1-cumProbs+probs))-1/len(l)\n",
    "ge=Operator(operator.ge,geExp)\n",
    "\n",
    "def leExp(l,r):\n",
    "    vals,freqs=np.unique(l.values,return_counts=True)\n",
    "    probs=freqs/len(l)\n",
    "    cumProbs=np.cumsum(probs)\n",
    "    return np.sum(probs*(cumProbs))-1/len(l)\n",
    "le=Operator(operator.le,leExp)\n",
    "\n",
    "def gtExp(l,r):\n",
    "    vals,freqs=np.unique(l.values,return_counts=True)\n",
    "    probs=freqs/len(l)\n",
    "    cumProbs=np.cumsum(probs)\n",
    "    return np.sum(probs*(1-cumProbs))\n",
    "gt=Operator(operator.gt,gtExp)\n",
    "\n",
    "def ltExp(l,r):\n",
    "    vals,freqs=np.unique(l.values,return_counts=True)\n",
    "    probs=freqs/len(l)\n",
    "    cumProbs=np.cumsum(probs)\n",
    "    return np.sum(probs*(cumProbs-probs))\n",
    "lt=Operator(operator.lt,ltExp)\n",
    "operatorMap={\n",
    "    \"EQUAL\":eq,\n",
    "    \"UNEQUAL\":ne,\n",
    "    \"LESS_EQUAL\":le,\n",
    "    \"GREATER_EQUAL\":ge,\n",
    "    \"LESS\":lt,\n",
    "    \"GREATER\":gt\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "class Predicate:\n",
    "    def __init__(self,l:str,op:Operator,r:str) -> None:\n",
    "        self.l=l\n",
    "        self.r=r\n",
    "        self.op=op\n",
    "        self.exp=None\n",
    "    def eval(self,df,t0,t1):\n",
    "        return self.op(t0[self.l],t1[self.r])\n",
    "    def expected(self,df):\n",
    "        if self.exp is None:\n",
    "            self.exp=self.op.expected(df.df[self.l],None)\n",
    "        return self.exp\n",
    "            \n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return '\"'+self.l +'\" '+self.op.__repr__()+' \"'+self.r+'\"'\n",
    "    def __hash__(self):\n",
    "        fields=(self.l,self.r)\n",
    "        hash_value = hash(fields)\n",
    "        return hash_value\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, Predicate):\n",
    "            sFields=(self.l,self.op,self.r)\n",
    "            oFields=(other.l,other.op,other.r)\n",
    "            return sFields==oFields\n",
    "        return False\n",
    "\n",
    "\n",
    "class DenialConstraint:\n",
    "    def __init__(self,preds) -> None:\n",
    "        self.preds=preds\n",
    "    def eval(self,df,t0,t1):\n",
    "        return sum([pred.eval(df,t0,t1) for pred in self.preds])\n",
    "    def coverage(self,df,t0s,t1s):\n",
    "        pos,neg=0,0\n",
    "        num=self.eval(df,t0s,t1s)\n",
    "        dclen=len(self.preds)\n",
    "        pos=(num==dclen).sum()\n",
    "        neg=(num<dclen).sum()\n",
    "\n",
    "                \n",
    "        return neg/(pos+neg)\n",
    "    def sampleCoverage(self,df,n=None):\n",
    "        nn=len(df.df)\n",
    "        if n is None:\n",
    "            n=nn**2\n",
    "        t0s = np.random.randint(0,len(df.df),n)\n",
    "        t1s = np.random.randint(0,len(df.df),n)\n",
    "        t1s=(t1s+(t1s==t0s)*np.random.randint(1,len(df.df),n))%len(df.df)\n",
    "        return self.coverage(df,t0s,t1s)\n",
    "    def expCoverage(self,df):\n",
    "        return 1-np.prod([pred.expected(df) for pred in self.preds])\n",
    "    def __repr__(self) -> str:\n",
    "        return \"![\"+\" & \".join([pred.__repr__() for pred in self.preds])+\"]\"\n",
    "\n",
    "\n",
    "class DenialConstraintSet:\n",
    "    def __init__(self,path,dataset,algorithm) -> None:        \n",
    "        self.predicates={}\n",
    "        opmap={\"==\":eq,\"<>\":ne,\">=\":ge,\"<=\":le,\">\":gt,\"<\":lt}\n",
    "        def getPred(c1,op,c2):\n",
    "            if (c1,c2,op) not in self.predicates:\n",
    "                self.predicates[(c1,c2,op)]=Predicate(c1,opmap[op],c2)\n",
    "            return self.predicates[(c1,c2,op)]\n",
    "        \n",
    "        self.DCs=[]\n",
    "        \n",
    "        with open(path) as f:\n",
    "            for line in f:\n",
    "                line=line.strip()[2:-1] #strip !(...)\n",
    "                preds=line.split('^')\n",
    "                regex=r't0\\.'+dataset+'\\.csv\\.([^=><]*)(==|<>|>=|<=|>|<)t1\\.'+dataset+'\\.csv\\.([^=><]*)'\n",
    "                if algorithm in ['ADCMiner','FastADC']:\n",
    "                    regex=r't0\\.([^=><]*) (==|<>|>=|<=|>|<) t1\\.([^=><]*)'\n",
    "                preds = [getPred(*re.match(regex,pred).groups()) for pred in preds]\n",
    "                self.DCs.append(DenialConstraint(preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discover DCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT FILE: ./datasets/Hospital.csv\n",
      "ERROR THRESHOLD: 0.01\n",
      " [Input] # of Tuples: 10000\n",
      " [Input] # of Attributes: 15\n",
      " [Predicate] Predicate space size: 30\n",
      "[FastADC] Pre-process time: 603ms\n",
      "  [CLUE] # of bits in clue: 15\n",
      "  [CLUE] task count: 435\n",
      " [Evidence] # of evidences: 286\n",
      " [Evidence] Accumulated evidence count: 99990000\n",
      "[FastADC] Evidence time: 799ms\n",
      " [AEI Start] 2024-02-04 21:17:09\n",
      " [AEI] Violate at most 999900 tuple pairs\n",
      "  [AEI] Inverting evidences...\n",
      "  [AEI] Min cover size: 92\n",
      "  [AEI] Total DC size: 92\n",
      "  [AEI] Min DC size : 92\n",
      "[FastADC] AEI time: 71ms\n",
      "[FastADC] Total computing time: 1473 ms\n",
      "\n",
      "\n",
      "Lines written to file successfully!\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets[6:7]:\n",
    "    for algorithm in algorithms[3:4]:\n",
    "        command='java -Xmx8g -cp {} Main {} 0.01 10000'.format(JARDir+algorithm+'.jar',dataDir+dataset+\".csv\")\n",
    "        result = subprocess.run(command, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcs=DenialConstraintSet(\"output.txt\",\"Hospital\",\"FastADC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dcs.DCs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds=Dataset(\"datasets/Hospital.csv\")\n",
    "ds.buildPLIs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=10000\n",
    "t0s = ds.randFields(n)\n",
    "t1s = ds.randFields(n)\n",
    "\n",
    "res=[ dc.coverage(ds,t0s,t1s) for dc in dcs.DCs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i,r in enumerate(res) if r<0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[![\"ZIP Code(String)\" eq \"ZIP Code(String)\"],\n",
       " ![\"Condition(String)\" ne \"Condition(String)\" & \"Measure Code(String)\" eq \"Measure Code(String)\"],\n",
       " ![\"Condition(String)\" ne \"Condition(String)\" & \"Measure Name(String)\" eq \"Measure Name(String)\"],\n",
       " ![\"County Name(String)\" eq \"County Name(String)\" & \"Sample(String)\" eq \"Sample(String)\"],\n",
       " ![\"County Name(String)\" eq \"County Name(String)\" & \"State(String)\" ne \"State(String)\"],\n",
       " ![\"StateAvg(String)\" eq \"StateAvg(String)\"],\n",
       " ![\"Measure Name(String)\" eq \"Measure Name(String)\" & \"Sample(String)\" eq \"Sample(String)\"],\n",
       " ![\"County Name(String)\" eq \"County Name(String)\" & \"Measure Name(String)\" eq \"Measure Name(String)\"],\n",
       " ![\"Condition(String)\" eq \"Condition(String)\" & \"County Name(String)\" eq \"County Name(String)\"],\n",
       " ![\"Condition(String)\" eq \"Condition(String)\" & \"Hospital Type(String)\" ne \"Hospital Type(String)\" & \"State(String)\" eq \"State(String)\"],\n",
       " ![\"Hospital Type(String)\" ne \"Hospital Type(String)\" & \"Measure Code(String)\" eq \"Measure Code(String)\"],\n",
       " ![\"Sample(String)\" eq \"Sample(String)\" & \"State(String)\" eq \"State(String)\"],\n",
       " ![\"Hospital Type(String)\" ne \"Hospital Type(String)\" & \"Measure Name(String)\" eq \"Measure Name(String)\"],\n",
       " ![\"Hospital Name(String)\" eq \"Hospital Name(String)\"],\n",
       " ![\"Measure Code(String)\" eq \"Measure Code(String)\" & \"Measure Name(String)\" ne \"Measure Name(String)\"],\n",
       " ![\"Measure Code(String)\" ne \"Measure Code(String)\" & \"Measure Name(String)\" eq \"Measure Name(String)\"],\n",
       " ![\"Phone Number(String)\" eq \"Phone Number(String)\"],\n",
       " ![\"Hospital Type(String)\" ne \"Hospital Type(String)\" & \"Sample(String)\" eq \"Sample(String)\"],\n",
       " ![\"County Name(String)\" eq \"County Name(String)\" & \"Hospital Type(String)\" ne \"Hospital Type(String)\"],\n",
       " ![\"Measure Name(String)\" eq \"Measure Name(String)\" & \"State(String)\" eq \"State(String)\"],\n",
       " ![\"Emergency Service(String)\" ne \"Emergency Service(String)\" & \"Sample(String)\" eq \"Sample(String)\"],\n",
       " ![\"County Name(String)\" eq \"County Name(String)\" & \"Emergency Service(String)\" ne \"Emergency Service(String)\"],\n",
       " ![\"Measure Code(String)\" eq \"Measure Code(String)\" & \"Sample(String)\" eq \"Sample(String)\"],\n",
       " ![\"County Name(String)\" eq \"County Name(String)\" & \"Measure Code(String)\" eq \"Measure Code(String)\"],\n",
       " ![\"Hospital Owner(String)\" eq \"Hospital Owner(String)\" & \"Sample(String)\" eq \"Sample(String)\"],\n",
       " ![\"Hospital Owner(String)\" eq \"Hospital Owner(String)\" & \"Measure Name(String)\" eq \"Measure Name(String)\"],\n",
       " ![\"Condition(String)\" eq \"Condition(String)\" & \"Hospital Owner(String)\" eq \"Hospital Owner(String)\" & \"Hospital Type(String)\" ne \"Hospital Type(String)\"],\n",
       " ![\"Measure Code(String)\" eq \"Measure Code(String)\" & \"State(String)\" eq \"State(String)\"],\n",
       " ![\"Condition(String)\" ne \"Condition(String)\" & \"Emergency Service(String)\" ne \"Emergency Service(String)\" & \"Hospital Type(String)\" ne \"Hospital Type(String)\" & \"State(String)\" ne \"State(String)\"],\n",
       " ![\"Hospital Owner(String)\" eq \"Hospital Owner(String)\" & \"Measure Code(String)\" eq \"Measure Code(String)\"],\n",
       " ![\"Provider Number(String)\" eq \"Provider Number(String)\"],\n",
       " ![\"City(String)\" eq \"City(String)\"],\n",
       " ![\"Emergency Service(String)\" ne \"Emergency Service(String)\" & \"Hospital Owner(String)\" eq \"Hospital Owner(String)\" & \"State(String)\" eq \"State(String)\"],\n",
       " ![\"Hospital Owner(String)\" eq \"Hospital Owner(String)\" & \"Hospital Type(String)\" ne \"Hospital Type(String)\" & \"State(String)\" eq \"State(String)\"]]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcs.DCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9963751279140795"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcs.DCs[8804].expCoverage(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[8804]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04550623851887257"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ltExp(ds.df['capital-loss float'],ds.df['capital-loss float'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "line='¬(t0.adult.csv.Native-country str<>t1.adult.csv.Native-country str^t0.adult.csv.capital-gain float<>t1.adult.csv.capital-gain float^t0.adult.csv.class str==t1.adult.csv.class str^t0.adult.csv.race str==t1.adult.csv.race str)'\n",
    "line=line[2:-1] #strip !(...)\n",
    "preds=line.split('^')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        True\n",
       "1        True\n",
       "2        True\n",
       "3        True\n",
       "4        True\n",
       "         ... \n",
       "32556    True\n",
       "32557    True\n",
       "32558    True\n",
       "32559    True\n",
       "32560    True\n",
       "Name: age int, Length: 32561, dtype: bool"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eq(ds.df['age int'],ds.df['age int'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
