{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# numpy 2.0 for bitwise count operations\n",
    "import numpy as np\n",
    "import json\n",
    "import operator\n",
    "import itertools \n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import subprocess\n",
    "import seaborn as sns\n",
    "from scipy.stats import beta,binom,betabinom\n",
    "#manual install from: https://github.com/allefeld/pytikz.git uncomment to install:\n",
    "#!pip install git+https://github.com/allefeld/pytikz.git\n",
    "import tikz\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets, algorithms and approximation factors used in the experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of rows of the datasets to consider.\n",
    "rowCount=2**15\n",
    "\n",
    "\n",
    "#Datasets\n",
    "dataDir=\"./datasets/\"\n",
    "datasetNames=[\n",
    "    \"airport\",\n",
    "    \"flights\",\n",
    "    \"food\",\n",
    "    \"Hospital\",\n",
    "    \"ncvoter\",\n",
    "    \"tax500k\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Algorithms\n",
    "JARDir=\"./algorithmJARs/\"\n",
    "algorithms=[\n",
    "    \"FastDC\",\n",
    "    \"Hydra\",\n",
    "    \"DCFinder\",\n",
    "    \"ADCMiner\",\n",
    "    \"FastADC\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Approximation factors to be used by algorithms\n",
    "aproximations=[\"0.00\",\"0.00000001\",\"0.000001\",\"0.0001\",\"0.01\"]\n",
    "aproxexp=[\"0\",\"10^{-8}\",\"10^{-6}\",\"10^{-4}\",\"10^{-2}\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classes used to represent datasets and Denial Constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Operator:\n",
    "    def __init__(self,func,expFunc) -> None:\n",
    "        self.func=func\n",
    "        self.expFunc=expFunc\n",
    "        self.neg=None\n",
    "        self.imp=None\n",
    "    def __call__(self,a,b):\n",
    "        return self.func(a,b)\n",
    "    def negate(self):\n",
    "        return Operator(operator.invert(self.func))\n",
    "    def expected(self,c1,c2):\n",
    "        return self.expFunc(c1,c2)\n",
    "    def __repr__(self) -> str:\n",
    "        return revopmap[self]\n",
    "    def __eq__(self, other: object) -> bool:\n",
    "        if isinstance(other, Operator):\n",
    "            return self.func==other.func\n",
    "        return False\n",
    "    def __hash__(self):\n",
    "        fields=(self.func)\n",
    "        hash_value = hash(fields)\n",
    "        return hash_value\n",
    "\n",
    "def eqExp(l,r):\n",
    "    n=sum(l)**2\n",
    "    return np.sum(l**2)/n\n",
    "       \n",
    "\n",
    "eq=Operator(operator.eq,eqExp)\n",
    "\n",
    "def neExp(l,r):\n",
    "    n=sum(l)\n",
    "    return 1-np.sum(l**2)/n**2\n",
    "ne=Operator(operator.ne,neExp)\n",
    "\n",
    "def geExp(l,r):\n",
    "    n=sum(l)\n",
    "    cumFreq=np.cumsum(l)\n",
    "    return np.sum(l*(cumFreq))/n**2\n",
    "ge=Operator(operator.ge,geExp)\n",
    "\n",
    "def leExp(l,r):\n",
    "    n=sum(l)\n",
    "    cumFreq=np.cumsum(l)\n",
    "    return np.sum(l*(n-cumFreq+l))/n**2\n",
    "le=Operator(operator.le,leExp)\n",
    "\n",
    "def gtExp(l,r):\n",
    "    n=sum(l)\n",
    "    cumFreq=np.cumsum(l)\n",
    "    return np.sum(l*(cumFreq-l))/n**2\n",
    "gt=Operator(operator.gt,gtExp)\n",
    "\n",
    "def ltExp(l,r):\n",
    "    n=sum(l)\n",
    "    cumFreq=np.cumsum(l)\n",
    "    return np.sum(l*(n-cumFreq))/n**2\n",
    "lt=Operator(operator.lt,ltExp)\n",
    "operatorMap={\n",
    "    \"EQUAL\":eq,\n",
    "    \"UNEQUAL\":ne,\n",
    "    \"LESS_EQUAL\":le,\n",
    "    \"GREATER_EQUAL\":ge,\n",
    "    \"LESS\":lt,\n",
    "    \"GREATER\":gt\n",
    "}\n",
    "\n",
    "opmap={\"==\":eq,\"<>\":ne,\">=\":ge,\"<=\":le,\">\":gt,\"<\":lt}\n",
    "revopmap={y:x for x,y in opmap.items()}\n",
    "\n",
    "eq.neg=ne\n",
    "ne.neg=eq\n",
    "gt.neg=le\n",
    "le.neg=gt\n",
    "lt.neg=ge\n",
    "ge.neg=lt\n",
    "\n",
    "eq.imp=[ge,le,eq]\n",
    "ne.imp=[ne]\n",
    "gt.imp=[gt,ge,ne]\n",
    "lt.imp=[lt,le,ne]\n",
    "ge.imp=[ge]\n",
    "le.imp=[le]\n",
    "\n",
    "\n",
    "#wrong implications to avoid DCs of the sort > -> !=\n",
    "eq.imp=[ge,le,eq]\n",
    "ne.imp=[ne,lt,gt]\n",
    "gt.imp=[gt,ge]\n",
    "lt.imp=[lt,le]\n",
    "ge.imp=[ge]\n",
    "le.imp=[le]\n",
    "\n",
    "\n",
    "class Predicate:\n",
    "    def __init__(self,l:str,op:Operator,r:str) -> None:\n",
    "        self.l=l\n",
    "        self.r=r\n",
    "        self.op=op\n",
    "        self.exp=None\n",
    "         \n",
    "\n",
    "            \n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return 't0.'+self.l +' '+self.op.__repr__()+' t1.'+self.r+''\n",
    "    def __hash__(self):\n",
    "        fields=(self.l,self.r)\n",
    "        hash_value = hash(fields)\n",
    "        return hash_value\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, Predicate):\n",
    "            sFields=(self.l,self.op,self.r)\n",
    "            oFields=(other.l,other.op,other.r)\n",
    "            return sFields==oFields\n",
    "        return False\n",
    "    def impliesPred(self,other):\n",
    "        #True if predicate being false implies other being false\n",
    "        return self.l==other.l and self.r==other.r and other.op.neg in self.op.neg.imp\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(self,file,**args):\n",
    "        self.columns=pd.read_csv(file,nrows=0).columns\n",
    "        self.header=[re.match(r'([^\\(\\)]*)(?:\\(| )([^\\(\\)]*)\\)?',col) for col in self.columns]\n",
    "        self.names=[match[1] for match in self.header]\n",
    "        typeMap={'String':str,'Integer':float,'Int':float,'Double':float,'int':float,'str':str,'float':float}\n",
    "        self.types={col:typeMap[match[2]] for col,match in zip(self.columns,self.header)}\n",
    "        \n",
    "        self.df=pd.read_csv(file,**args,dtype=self.types)\n",
    "        for i,col in enumerate(self.columns):\n",
    "            self.df[col]=self.df[col].astype(self.types[col])\n",
    "        \n",
    "    def randRows(self,n):\n",
    "        ids=np.random.randint(0,len(self.df),n)\n",
    "        return self.df.iloc[ids]\n",
    "    def randFields(self,n):\n",
    "        return pd.DataFrame({col:dfs[col].iloc[list(np.random.randint(0,len(dfs),n))].values for dfs in [self.df] for col in dfs.columns})\n",
    "\n",
    "    def buildPLIs(self):\n",
    "        self.PLI= {col:self.df.groupby(by=col).groups for col in self.df}\n",
    "        self.PLILen={col:np.array([len(self.PLI[col][v])for v in self.PLI[col]]) for col in self.df}\n",
    "        self.vals={col:np.array([v for v in self.PLI[col]]) for col in self.df}\n",
    "    def shuffle(self):\n",
    "        self.df=self.randFields(len(self.df))\n",
    "\n",
    "    def buildPreds(self):\n",
    "        self.preds=[]\n",
    "        self.predMap={}\n",
    "        self.colPreds=[]\n",
    "        self.predCols=[]\n",
    "        \n",
    "        for col in self.columns:\n",
    "            ops=[eq,ne] if self.types[col] ==str else [eq,ne,gt,ge,lt,le]\n",
    "            self.colPreds.append([]) \n",
    "            for op in ops:\n",
    "                pred=Predicate(col,op,col)\n",
    "                self.predMap[(col,op,col)]=len(self.preds)\n",
    "                self.predCols.append(len(self.colPreds))\n",
    "                self.colPreds[-1].append(len(self.preds))\n",
    "                self.preds.append(pred)\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "    \n",
    "    def buildEvi(self):\n",
    "        n=len(self.df)\n",
    "        m=len(self.preds)\n",
    "        self.eviSize=n*(n-1)\n",
    "\n",
    "        self.evi=[None]*m\n",
    "        self.predProbs=[None]*m\n",
    "        \n",
    "       \n",
    "        for p in range(m):\n",
    "            pred=self.preds[p]\n",
    "            col=self.df[pred.l]\n",
    "            evis=[]\n",
    "            for i in range(n):\n",
    "                c1=col.iloc[i]\n",
    "                c2=col.iloc[i+1:n]\n",
    "                evis.append(pred.op(c1,c2))\n",
    "                c2=col.iloc[:i]\n",
    "                evis.append(pred.op(c1,c2))\n",
    "\n",
    "            allTPs=np.concatenate(evis)\n",
    "            self.evi[p]=np.packbits(allTPs,axis=0,bitorder='little')\n",
    "            self.predProbs[p]=allTPs.sum()/(n*(n-1))*2\n",
    "        self.sortedPreds=sorted(range(len(self.predProbs)),key=lambda i:self.predProbs[i])\n",
    "                \n",
    "\n",
    "\n",
    "class DenialConstraint:\n",
    "    def __init__(self,preds) -> None:\n",
    "        self.preds=preds\n",
    "        \n",
    "    def __sub__(self,other):\n",
    "        return DenialConstraint(self.preds-other.preds)\n",
    "    def __le__(self,other):\n",
    "        other:DenialConstraint=other\n",
    "        return all([ any([p==pp for pp in other.preds]) for p in self.preds])\n",
    "\n",
    "    def __eq__(self, value: object) -> bool:\n",
    "        return self<=value and value<=self\n",
    "    def __repr__(self) -> str:\n",
    "        return \"Â¬(\"+\" ^ \".join([pred.__repr__() for pred in self.preds])+\")\"\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "class DenialConstraintSet:\n",
    "    def __init__(self,path,dataset,dss,algorithm) -> None:        \n",
    "        self.predMap={}\n",
    "        self.preds=[]\n",
    "        self.dss=dss\n",
    "        opmap={\"==\":eq,\"<>\":ne,\">=\":ge,\"<=\":le,\">\":gt,\"<\":lt}\n",
    "        def getPred(c1,op,c2):\n",
    "            op=opmap[op]\n",
    "            return dss.predMap[(c1,op,c2)]\n",
    "        \n",
    "        self.DCs=[]\n",
    "        \n",
    "        with open(path) as f:\n",
    "            for line in f:\n",
    "                line=line.strip()[2:-1] #strip !(...)\n",
    "                preds=line.split('^')\n",
    "                regex=r't0\\.'+dataset+'\\.csv\\.([^=><]*)(==|<>|>=|<=|>|<)t1\\.'+dataset+'\\.csv\\.([^=><]*)'\n",
    "                if algorithm in ['ADCMiner','FastADC','ours']:\n",
    "                    regex=r't0\\.([^=><]*) (==|<>|>=|<=|>|<) t1\\.([^=><]*)'\n",
    "                preds = [getPred(*re.match(regex,pred.strip()).groups()) for pred in preds]\n",
    "                self.DCs.append(preds)\n",
    "\n",
    "    def buildGraph(self):\n",
    "        self.root=[{},None]\n",
    "        for dc in self.DCs:\n",
    "            node=self.root\n",
    "            for pred in sorted(dc):\n",
    "                if pred not in node[0]:\n",
    "                    node[0][pred]=[{},None]\n",
    "                node=node[0][pred]\n",
    "            node[1]=dc\n",
    "\n",
    "    def getReduced(self):\n",
    "       \n",
    "        notImplied=[True]*len(self.DCs)\n",
    "\n",
    "        def impliesDC(dc1,dc2):\n",
    "            return all([any([self.dss.preds[pred].impliesPred(self.dss.preds[otherpred]) for otherpred in dc2]) for pred in dc1])\n",
    "\n",
    "        for i,dc1 in enumerate(self.DCs):\n",
    "            for j,dc2 in enumerate(self.DCs):\n",
    "                if impliesDC(dc1,dc2):\n",
    "                    if impliesDC(dc2,dc1):\n",
    "                        notImplied[j]=notImplied[j] and j<=i\n",
    "                    else:\n",
    "                        notImplied[j]=False\n",
    "        return [dc for i,dc in enumerate(self.DCs) if notImplied[i]]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to obtain the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load datasets\n",
    "datasets={}\n",
    "for name in datasetNames:\n",
    "    print(name)\n",
    "    datasets[name]=Dataset(dataDir+name+\".csv\",nrows=rowCount,encoding='unicode_escape')\n",
    "    datasets[name].buildPLIs()\n",
    "    datasets[name].buildPreds()\n",
    "    #datasets[name].buildEvi()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discover DCs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Runs every combination algorithm/dataset/approximation and stores the results. Long execution time, compressed results stored from previous executions can be loaded with the last cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "start=0\n",
    "for dataset in datasetNames:\n",
    "    for algorithm in algorithms:\n",
    "        for aprox in [\"0.00\",\"0.00000001\",\"0.000001\",\"0.0001\",\"0.01\"] if algorithm not in ['Hydra','FastDC'] else [\"0.00\"]:\n",
    "            i+=1\n",
    "            if i<start:\n",
    "                continue\n",
    "            print(f\"---------------ITERATION: {i}\")\n",
    "            print(\"RUN: {}_{}_{}\".format(algorithm,dataset,aprox))\n",
    "            #Use -Xmx12g if needed\n",
    "            command='java -jar {} {} {} {}'.format(JARDir+algorithm+'.jar',dataDir+dataset+\".csv\",aprox,rowCount)\n",
    "            result = subprocess.run(command, shell=True)\n",
    "            print(\"MOVE: {}_{}_{}\".format(algorithm,dataset,aprox))\n",
    "            command='mv output.txt results/{}_{}_{}'.format(algorithm,dataset,aprox)\n",
    "            result = subprocess.run(command, shell=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results \n",
    "%cd ./results/\n",
    "!zip  ./DiscoveredDCs.zip ./*_*_*\n",
    "%cd -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results \n",
    "%cd ./results/\n",
    "!unzip  -n ./DiscoveredDCs.zip\n",
    "%cd -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute DC satisfactions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load DC discovery algorithm results\n",
    "discoveredDCs={}\n",
    "for dataset in datasetNames:\n",
    "    ds=datasets[dataset]\n",
    "    for algorithm in algorithms[:]:\n",
    "        aproxs=[\"0.00\",\"0.00000001\",\"0.000001\",\"0.0001\",\"0.01\"] if algorithm not in ['Hydra','FastDC'] else [\"0.00\"]\n",
    "        for aprox in aproxs:\n",
    "            print(\"{}_{}_{}\".format(algorithm,dataset,aprox))\n",
    "            dcs=DenialConstraintSet(\"results/{}_{}_{}\".format(algorithm,dataset,aprox),dataset,ds,algorithm)\n",
    "            discoveredDCs[(algorithm,dataset,aprox)]={frozenset(preds) for preds in dcs.DCs}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every discovered DC (and some subsets) compute statistics like satisfaction and expected satisfaction under independence. Long execution time, cell before last allows to load previously saved results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute satisfaction of accepted DCs on data\n",
    "results={}\n",
    "for dataset in datasetNames:\n",
    "    print(\"Load dataset\"+str(dataset))\n",
    "    ds=Dataset(dataDir+dataset+\".csv\",nrows=2**12,encoding='unicode_escape')\n",
    "    ds.buildPLIs()\n",
    "    ds.buildPreds()\n",
    "    ds.buildEvi()\n",
    "    print(\"Loaded dataset \"+str(dataset))\n",
    "    for algorithm in algorithms[:]:\n",
    "        aproxs=[\"0.00\",\"0.00000001\",\"0.000001\",\"0.0001\",\"0.01\"] if algorithm not in ['Hydra','FastDC'] else [\"0.00\"]\n",
    "        for aprox in aproxs:\n",
    "            print(\"{}_{}_{}\".format(algorithm,dataset,aprox))\n",
    "\n",
    "            dcs=DenialConstraintSet(\"results/{}_{}_{}\".format(algorithm,dataset,aprox),dataset,ds,algorithm)\n",
    "            dcs.buildGraph()\n",
    "            res={}\n",
    "            def search(b,s,x,node,prob=1):\n",
    "                res[s]=(np.sum(np.bitwise_count(x))/ds.eviSize,prob,node[1] is not None)\n",
    "\n",
    "                for i in range(b,len(ds.preds)):\n",
    "                    if i in node[0]:\n",
    "                        search(i+1,s|{i},np.bitwise_and(x,ds.evi[i]),node[0][i],prob*ds.predProbs[i])\n",
    "\n",
    "            search(0,frozenset(),np.full((ds.eviSize//8,),255,dtype=np.uint8),dcs.root)\n",
    "\n",
    "            results[(algorithm,dataset,aprox)]=res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "with open(\"results/DCSatisfactions\", 'wb') as file:\n",
    "        pickle.dump(results,file)\n",
    "\n",
    "%cd ./results/\n",
    "!zip  ./DCSatisfactions.zip ./DCSatisfactions\n",
    "%cd -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results \n",
    "%cd ./results/\n",
    "!unzip  -n ./DCSatisfactions.zip\n",
    "%cd -\n",
    "\n",
    "with open(\"results/DCSatisfactions\", 'rb') as file:\n",
    "        results=pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DC Satisfactions are computed for every DC in the set, along with the necessary subsets to reach them from the empty set. See buildGraph() function.\n",
    "#For experimenting, we need all the information\n",
    "#For plotting, only information about discovered DCs is needed\n",
    "#Run if using the notebook as is to reproduce the plots\n",
    "results={x: {dc:results[x][dc] for dc in results[x] if results[x][dc][2]}  for x in results}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute number of tuple pairs satisfying each node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enumerates sets of predicates up to a certain size and computes its satisfaction. Long execution time, last cell allows loading precomputed results from previous executions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def powerset(iterable):\n",
    "    \"powerset([1,2,3]) --> () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)\"\n",
    "    s = list(iterable)\n",
    "    return itertools.chain.from_iterable(itertools.combinations(s, r) for r in range(len(s)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Our results\n",
    "depth=4\n",
    "DCCounts={}\n",
    "for dataset in datasetNames:\n",
    "    \n",
    "    print(\"Load dataset \"+str(dataset))\n",
    "    ds=Dataset(dataDir+dataset+\".csv\",nrows=rowCount,encoding='unicode_escape')\n",
    "    ds.buildPLIs()\n",
    "    ds.buildPreds()\n",
    "    ds.buildEvi()\n",
    "    print(\"Loaded dataset \"+str(dataset))\n",
    "    counts={}\n",
    "    \n",
    "    def search(preds,cols,x):\n",
    "\n",
    "        \n",
    "        counts[preds]=np.bitwise_count(x).sum()\n",
    "        if len(preds)>=depth:\n",
    "             return\n",
    "            \n",
    "        for pred in ds.sortedPreds:\n",
    "                ncol=ds.predCols[pred]\n",
    "                if ncol in cols:\n",
    "                    continue\n",
    "                npreds=preds|{pred}\n",
    "                ncols=cols|{ncol}\n",
    "                if npreds in counts:\n",
    "                    continue\n",
    "\n",
    "                newx=np.bitwise_and(x,ds.evi[pred])\n",
    "                    \n",
    "                search(npreds,ncols,newx)\n",
    "\n",
    "    search(frozenset(),frozenset(),np.full((ds.eviSize//8,),255,dtype=np.uint8))\n",
    "\n",
    "    DCCounts[dataset]=counts\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "with open(\"results/DCCounts\", 'wb') as file:\n",
    "        pickle.dump(DCCounts,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results\n",
    "with open(\"results/DCCounts\", 'rb') as file:\n",
    "        DCCounts=pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discover all atomic sets of predicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enumerates all sets of predicates up to a certain size and determines if they are atomic using precomputed satisfactions from before. \n",
    "\n",
    "We only explore up to size 4 as no atomic (or sound) DC of size 5 or more was found during research. \n",
    "\n",
    "To determine atomicity we check if independent predicates are added to form the DC. Any statistical test to compare probabilities or successes (Binomial) may be used. For efficiency, we used an accurate normal approximation to the log odds ratio of two beta distributions, and determine a set of predicates has lower satisfaction than expected when the log odds ratio it is two standard deviations from 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "yconst=0.5772156649\n",
    "def y1():\n",
    "    mem=[-yconst]\n",
    "    def f(n):\n",
    "        while len(mem)<n:\n",
    "            mem.append(mem[-1]+1/len(mem))\n",
    "        return mem[n-1]\n",
    "    return f\n",
    "y1=y1()\n",
    "\n",
    "\n",
    "def y2():\n",
    "    mem=[np.pi**2/6]\n",
    "    def f(n):\n",
    "        while len(mem)<n:\n",
    "            mem.append(mem[-1]-1/len(mem)**2)\n",
    "        return mem[n-1]\n",
    "    return f\n",
    "y2=y2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Our results\n",
    "depth=4\n",
    "DCResults={}\n",
    "SoundDCs={}\n",
    "for dataset in datasetNames:\n",
    "    print(dataset)\n",
    "    print(\"Load dataset \"+str(dataset))\n",
    "    ds=Dataset(dataDir+dataset+\".csv\",nrows=rowCount,encoding='unicode_escape')\n",
    "    ds.buildPLIs()\n",
    "    ds.buildPreds()\n",
    "    ds.buildEvi()\n",
    "    print(\"Loaded dataset \"+str(dataset))\n",
    "    counts=DCCounts[dataset]\n",
    "    DCResult=[]\n",
    "    SoundDC=set()\n",
    "    visited=set()\n",
    "    \n",
    "    def search(preds,cols):\n",
    "        if preds in visited:\n",
    "            return\n",
    "        visited.add(preds)                \n",
    "            \n",
    "        for pred in ds.sortedPreds:\n",
    "                ncol=ds.predCols[pred]\n",
    "                if ncol in cols:\n",
    "                    continue\n",
    "                npreds=preds|{pred}\n",
    "                ncols=cols|{ncol}\n",
    "                if len(npreds)>=depth:\n",
    "                    return\n",
    "                a1=int(counts[npreds])\n",
    "                b1=int(counts[preds])-a1\n",
    "\n",
    "                atomic=True\n",
    "\n",
    "                for subPreds in powerset(preds):\n",
    "                    subPreds=frozenset(subPreds)\n",
    "                    npreds2=subPreds|{pred}\n",
    "\n",
    "                    a2=int(counts[npreds2])\n",
    "                    b2=int(counts[subPreds])-a2\n",
    "                    \n",
    "                    u=y1(a1+1)-y1(b1+1)-y1(a2+1)+y1(b2+1)\n",
    "\n",
    "                    s=np.sqrt(y2(a1+1)+y2(b1+1)+y2(a2+1)+y2(b2+1))\n",
    "\n",
    "                    if u+2*s>0:\n",
    "                        atomic=False\n",
    "                        break\n",
    "                if atomic:\n",
    "                    SoundDC.add(npreds)\n",
    "                    if a1==0:\n",
    "                        DCResult.append((preds,pred))\n",
    "                    else:\n",
    "                        search(npreds,ncols)\n",
    "\n",
    "    search(frozenset(),frozenset())\n",
    "\n",
    "    DCResults[dataset]=DCResult\n",
    "    SoundDCs[dataset]=SoundDC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "with open(\"results/DCResults\", 'wb') as file:\n",
    "        pickle.dump(DCResults,file)\n",
    "with open(\"results/DCSound\", 'wb') as file:\n",
    "        pickle.dump(SoundDCs,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results\n",
    "with open(\"results/DCResults\", 'rb') as file:\n",
    "        DCResults=pickle.load(file)\n",
    "with open(\"results/DCSound\", 'rb') as file:\n",
    "        SoundDCs=pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save sound DCs\n",
    "def getPred(i,ds):\n",
    "    return (ds.preds[i])\n",
    "for dataset in datasetNames:\n",
    "    print(\"Load dataset \"+str(dataset))\n",
    "    ds=Dataset(dataDir+dataset+\".csv\",nrows=rowCount,encoding='unicode_escape')\n",
    "    ds.buildPLIs()\n",
    "    ds.buildPreds()\n",
    "    exact=DenialConstraintSet(\"results/FastDC_{}_0.00\".format(dataset),dataset,ds,\"FastDC\")\n",
    "    exact=[frozenset([getPred(xx,ds) for xx in x]) for x in exact.DCs]\n",
    "    dcs=set({})\n",
    "    print(\"Loaded dataset \"+str(dataset))\n",
    "    with open(\"soundDCs/{}\".format(dataset),\"w\") as f:\n",
    "        for dc in [ DenialConstraint([ getPred(p,ds) for p in preds]+[getPred(pred,ds)]) for preds,pred in DCResults[dataset]]:\n",
    "            s=frozenset(dc.preds)\n",
    "            if s not in dcs:\n",
    "                if s not in exact:\n",
    "                    pass\n",
    "                else:\n",
    "                    dcs.add(s)\n",
    "                    f.write(dc.__repr__()+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter results to only keep sound DCs. Used to decide if the plots are to be made from original results or results with our soundness rule\n",
    "#prevResults=results\n",
    "filteredResults={}\n",
    "for ex in discoveredDCs:\n",
    "    alg,dataset,ap=ex\n",
    "    if dataset not in datasetNames:\n",
    "        continue\n",
    "    ours=SoundDCs[dataset]\n",
    "    discovered=discoveredDCs[ex]\n",
    "    filteredResults[ex] = {dc for dc in discovered if (len(dc)==1 or dc in ours)}\n",
    "results=filteredResults\n",
    "\n",
    "#To go back to using all DCs instead of only sound ones, reload variable results in section \"Compute number of tuple pairs satisfying each node\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability under independence evolution as data increases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discovers DCs with different dataset sizes and measures the trend of the expected probability of discovered DCs. Long execution time. Last cell loads saved results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discover DCs with varying dataset sizes\n",
    "i=0\n",
    "start=0\n",
    "for dataset in datasetNames[-1:]:\n",
    "    for algorithm in algorithms[-1:]:\n",
    "        for aprox in  [\"0.00\"]:\n",
    "            for nrows in range(500,20500,500):\n",
    "                i+=1\n",
    "                if i<start:\n",
    "                    continue\n",
    "                print(f\"---------------ITERATION: {i}\")\n",
    "                print(\"RUN: {}_{}_{}_{}\".format(algorithm,dataset,aprox,nrows))\n",
    "                command='java -Xmx12g -jar {} {} {} {}'.format(JARDir+algorithm+'.jar',dataDir+dataset+\".csv\",aprox,nrows)\n",
    "                result = subprocess.run(command, shell=True)\n",
    "                print(\"MOVE: {}_{}_{}_{}\".format(algorithm,dataset,aprox,nrows))\n",
    "                command='mv output.txt results/{}_{}_{}_{}'.format(algorithm,dataset,aprox,nrows)\n",
    "                result = subprocess.run(command, shell=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds=Dataset(dataDir+datasetNames[-1]+\".csv\",nrows=rowCount,encoding='unicode_escape')\n",
    "ds.buildPreds()\n",
    "ds.buildPLIs()\n",
    "ds.buildEvi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results \n",
    "%cd ./results/\n",
    "!zip  ./VaryingDataDCs.zip ./*_*_*_*\n",
    "%cd -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results \n",
    "%cd ./results/\n",
    "!unzip  -n ./VaryingDataDCs.zip\n",
    "%cd -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DC sets plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each code block defines a function to generate tikz pictures of DC Lengths, DC Precision, and DC independence. There are two sets of DCs for which these plots are shown in the paper:\n",
    "- Full sets of discovered DCs\n",
    "- Sets of discovered DCs that are sound\n",
    "\n",
    "The variable \"results\" controls which of them is to be used:\n",
    "- For the full sets of discovered DCs, the direct results from Section \"Compute DC satisfactions\" can be used. Simply run the last two cells (load results, filter results to keep discovered DCs), and proceed below.\n",
    "- For the sets of discovered DCs that are sound, the direct results from Section \"Discover all atomic sets of predicates\" can be used. As before, load results and filter them with the final cell of the section, and proceed below.\n",
    "\n",
    "Choose which figure to generate and run the last cell to obtain the tikz figure. The figures shown in the paper are:\n",
    "\n",
    "- Figure 1: DC Lengths Vertical with full sets of discovered DCs\n",
    "- Figure 2: DC Precision Vertical with full sets of discovered DCs\n",
    "- Figure 3: DC Independence with full sets of discovered DCs\n",
    "- Figure 5: DC soundness with full sets of discovered DCs\n",
    "- Figure 6: DC Lengths Vertical with sound sets of discovered DCs\n",
    "- Figure 7: DC Precision Vertical with sound sets of discovered DCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DC Lengths Vertical\n",
    "algoWidth=2\n",
    "datasetHeight=2\n",
    "\n",
    "\n",
    "imgWidth=algoWidth*len(algorithms) -1.4\n",
    "imgHeight=datasetHeight*len(datasetNames)\n",
    "\n",
    "aproxOffset=algoWidth*0.1\n",
    "aproxWidth=(algoWidth-2*aproxOffset)/len(aproxexp)\n",
    "\n",
    "barWidth=aproxWidth*0.7\n",
    "barOffset=(aproxWidth-barWidth)/2\n",
    "\n",
    "barHeight=datasetHeight*0.9\n",
    "barHOffset=(datasetHeight-barHeight)/2\n",
    "\n",
    "buckets=8\n",
    "legendBuckedWidth=0.2\n",
    "legendBucketSpace=0.8\n",
    "\n",
    "colors=[sns.color_palette(palette='Accent')[i] for i in range(buckets)]\n",
    "def image(pic):\n",
    "    #pic.draw(tikz.rectangle((imgWidth,imgHeight)))\n",
    "\n",
    "    for d,dataset in enumerate(datasetNames):\n",
    "        drawDataset(pic,d,d*datasetHeight)\n",
    "    drawLegend(pic)\n",
    "\n",
    "def drawDataset(pic,d,y):\n",
    "    for a,algorithm in enumerate(algorithms):\n",
    "        drawAlgorithm(pic,d,a,a*algoWidth,y)\n",
    "    pic.draw((imgWidth+0.3,y+datasetHeight/2),tikz.node(datasetNames[d],rotate='-90'))\n",
    "    pic.draw((0,y+barHOffset),tikz.rectangle((imgWidth,y+barHOffset+barHeight)),color='black')\n",
    "\n",
    "    pic.draw((-0.1,y+barHOffset),tikz.node(\"\\\\scriptsize 0\\\\%\",anchor=' east'))\n",
    "    pic.draw((-0.1,y-barHOffset+datasetHeight),tikz.node(\"\\\\scriptsize \"+\"100\\\\%\",anchor=' east'))\n",
    "\n",
    "\n",
    "\n",
    "def drawAlgorithm(pic,d,a,x,y):\n",
    "    #pic.draw((x,y),tikz.rectangle((x+algoWidth,y+datasetHeight)),color='black')\n",
    "    for ap,aprox in enumerate(aproxexp):\n",
    "        drawAprox(pic,d,a,ap,x+aproxOffset+ap*aproxWidth-0.7*min(a,2),y)\n",
    "        if a<2:\n",
    "            break\n",
    "\n",
    "    if d==0:\n",
    "        pic.draw((x+algoWidth/2-0.7*min(a,2)-(0 if a>=2 else 0.5),y-0.8),tikz.node(algorithms[a]))\n",
    "\n",
    "\n",
    "def drawAprox(pic,d,a,ap,x,y):\n",
    "\n",
    "    res=results[(algorithms[a],datasetNames[d],aproximations[ap])]\n",
    "    bins=np.zeros((buckets,))\n",
    "    for dc in res:\n",
    "        l=len(dc)-1\n",
    "        l=min(l,buckets-1)\n",
    "        bins[l]+=1\n",
    "    \n",
    "    bins=np.cumsum(bins)\n",
    "    bins=bins/bins[-1]\n",
    "    bins= np.nan_to_num(bins,nan=0)\n",
    "    barY=0\n",
    "    \n",
    "    for i in range(len(bins)):\n",
    "        pic.definecolor(\"tmp\",'RGB',\",\".join([str(255*x) for x in colors[i]]))\n",
    "        pic.draw((x+barOffset,y+barHOffset+barY*barHeight),tikz.rectangle((x+barOffset+barWidth,y+barHOffset+bins[i]*barHeight)),fill='tmp')\n",
    "        barY=bins[i]\n",
    "\n",
    "\n",
    "    if d==0  :\n",
    "        pic.draw((x+barWidth/2,y-0.3),tikz.node(\"\\\\scriptsize$\"+aproxexp[ap]+\"$\",rotate='-90'))\n",
    "\n",
    "\n",
    "def drawLegend(pic):\n",
    "    x=imgWidth/2\n",
    "    \n",
    "    legendwidth=imgWidth\n",
    "    legendHeight=legendBuckedWidth+0.4\n",
    "    y=imgHeight+0.2+ legendHeight\n",
    "\n",
    "    pic.draw((x-legendwidth/2,y),tikz.rectangle((x+legendwidth/2,y-legendHeight)),color='black')\n",
    "    pic.draw((0.5,y-0.35),tikz.node(\"$\\\\mathbf{|\\\\varphi|:}$\",anchor='center'))\n",
    "\n",
    "    r=legendBuckedWidth\n",
    "    for i in range(buckets):\n",
    "        xx=x-legendwidth/2+legendBucketSpace+legendBuckedWidth/2+(legendBucketSpace+legendBuckedWidth)*i\n",
    "        xx=xx*0.9+0.6\n",
    "        yy=y-0.35\n",
    "        pic.definecolor(\"tmp\",'RGB',\",\".join([str(255*c) for c in colors[i]]))\n",
    "        pic.draw((xx-r/2,yy-r/2),tikz.rectangle((xx+r/2,yy+r/2)),fill='tmp')\n",
    "        txt=str(i+1)\n",
    "        if i==buckets-1:\n",
    "            txt+=\"+\"\n",
    "        pic.draw((xx+0.1,yy),tikz.node(txt,anchor='west'))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DC Lengths Horizontal\n",
    "algoWidth=2\n",
    "datasetHeight=2\n",
    "\n",
    "\n",
    "imgWidth=algoWidth*len(datasetNames)\n",
    "imgHeight=datasetHeight*len(algorithms)\n",
    "\n",
    "aproxOffset=algoWidth*0.1\n",
    "aproxWidth=(algoWidth-2*aproxOffset)/len(aproxexp)\n",
    "\n",
    "barWidth=aproxWidth*0.7\n",
    "barOffset=(aproxWidth-barWidth)/2\n",
    "\n",
    "barHeight=datasetHeight*0.9\n",
    "barHOffset=(datasetHeight-barHeight)/2\n",
    "\n",
    "buckets=8\n",
    "legendBuckedWidth=0.2\n",
    "legendBucketSpace=0.4\n",
    "\n",
    "colors=[sns.color_palette(palette='Accent')[i] for i in range(buckets)]\n",
    "def image(pic):\n",
    "    #pic.draw(tikz.rectangle((imgWidth,imgHeight)))\n",
    "\n",
    "    for a,dataset in enumerate(algorithms):\n",
    "        drawAlgorithm(pic,a,(len(algorithms)-1-a)*datasetHeight)\n",
    "    drawLegend(pic)\n",
    "\n",
    "def drawAlgorithm(pic,a,y):\n",
    "    for d,_ in  enumerate(datasetNames):\n",
    "        drawDataset(pic,a,d,d*algoWidth,y)\n",
    "    pic.draw((imgWidth+0.3,y+datasetHeight/2),tikz.node(algorithms[a],rotate='-90'))\n",
    "    pic.draw((0,y+barHOffset),tikz.rectangle((imgWidth,y+barHOffset+barHeight)),color='black')\n",
    "\n",
    "    pic.draw((-0.1,y+barHOffset),tikz.node(\"\\\\scriptsize 0\\\\%\",anchor=' east'))\n",
    "    pic.draw((-0.1,y-barHOffset+datasetHeight),tikz.node(\"\\\\scriptsize \"+\"100\\\\%\",anchor=' east'))\n",
    "\n",
    "\n",
    "\n",
    "def drawDataset(pic,a,d,x,y):\n",
    "    #pic.draw((x,y),tikz.rectangle((x+algoWidth,y+datasetHeight)),color='black')\n",
    "    for ap,aprox in enumerate(aproxexp):\n",
    "        drawAprox(pic,d,a,ap,x+aproxOffset+ap*aproxWidth,y)\n",
    "        if a<2:\n",
    "            break\n",
    "\n",
    "    if a==len(algorithms)-1:\n",
    "        pic.draw((x+algoWidth/2,y-0.8),tikz.node(datasetNames[d]))\n",
    "\n",
    "\n",
    "def drawAprox(pic,d,a,ap,x,y):\n",
    "\n",
    "    res=results[(algorithms[a],datasetNames[d],aproximations[ap])]\n",
    "    bins=np.zeros((buckets,))\n",
    "    for dc in res:\n",
    "        l=len(dc)-1\n",
    "        l=min(l,buckets-1)\n",
    "        bins[l]+=1\n",
    "    \n",
    "    bins=np.cumsum(bins)\n",
    "    bins=bins/bins[-1]\n",
    "    bins= np.nan_to_num(bins,nan=0)\n",
    "    barY=0\n",
    "    \n",
    "    for i in range(len(bins)):\n",
    "        pic.definecolor(\"tmp\",'RGB',\",\".join([str(255*x) for x in colors[i]]))\n",
    "        pic.draw((x+barOffset,y+barHOffset+barY*barHeight),tikz.rectangle((x+barOffset+barWidth,y+barHOffset+bins[i]*barHeight)),fill='tmp')\n",
    "        barY=bins[i]\n",
    "\n",
    "\n",
    "    if a==len(algorithms)-1  :\n",
    "        pic.draw((x+barWidth/2,y-0.3),tikz.node(\"\\\\scriptsize$\"+aproxexp[ap]+\"$\",rotate='-90'))\n",
    "\n",
    "\n",
    "def drawLegend(pic):\n",
    "    \n",
    "    \n",
    "    legendwidth=buckets*legendBuckedWidth+ (buckets+1)*legendBucketSpace\n",
    "    legendHeight=legendBucketSpace*2+legendBuckedWidth+0.6\n",
    "    legendwidth,legendHeight=legendHeight,legendwidth\n",
    "    x=imgWidth + 0.2 +legendwidth/2\n",
    "    y=imgHeight/2 - legendHeight/2\n",
    "\n",
    "    pic.draw((x-legendBuckedWidth/2-legendBucketSpace/2,y),tikz.rectangle((x+legendwidth/2,y+legendHeight)),color='black')\n",
    "    r=legendBuckedWidth\n",
    "    for i in range(buckets):\n",
    "        yy=y+legendBucketSpace+legendBuckedWidth/2+(legendBucketSpace+legendBuckedWidth)*i\n",
    "        xx=x\n",
    "        pic.definecolor(\"tmp\",'RGB',\",\".join([str(255*c) for c in colors[i]]))\n",
    "        pic.draw((xx-r/2,yy-r/2),tikz.rectangle((xx+r/2,yy+r/2)),fill='tmp')\n",
    "        txt=str(i+1)\n",
    "        if i==buckets-1:\n",
    "            txt+=\"+\"\n",
    "        pic.draw((xx+r,yy),tikz.node(txt,anchor='west'))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DC precision Vertical\n",
    "algoWidth=2\n",
    "datasetHeight=2\n",
    "\n",
    "\n",
    "imgWidth=algoWidth*len(algorithms)-1.4\n",
    "imgHeight=datasetHeight*len(datasetNames)\n",
    "\n",
    "aproxOffset=algoWidth*0.1\n",
    "aproxWidth=(algoWidth-2*aproxOffset)/len(aproxexp)\n",
    "\n",
    "barWidth=aproxWidth*0.7\n",
    "barOffset=(aproxWidth-barWidth)/2\n",
    "\n",
    "barHeight=datasetHeight*0.9\n",
    "barHOffset=(datasetHeight-barHeight)/2\n",
    "\n",
    "buckets=2\n",
    "legendBuckedWidth=0.2\n",
    "legendBucketSpace=0.8\n",
    "\n",
    "colors=[(0.9,0,0),(0,0.9,0)]\n",
    "def image(pic):\n",
    "    #pic.draw(tikz.rectangle((imgWidth,imgHeight)))\n",
    "\n",
    "    for d,dataset in enumerate(datasetNames):\n",
    "        drawDataset(pic,d,d*datasetHeight)\n",
    "    drawLegend(pic)\n",
    "\n",
    "def drawDataset(pic,d,y):\n",
    "    for a,algorithm in enumerate(algorithms):\n",
    "        drawAlgorithm(pic,d,a,a*algoWidth,y)\n",
    "    pic.draw((imgWidth+0.3,y+datasetHeight/2),tikz.node(datasetNames[d],rotate='-90'))\n",
    "    pic.draw((0,y+barHOffset),tikz.rectangle((imgWidth,y+barHOffset+barHeight)),color='black')\n",
    "\n",
    "    sizes=[ len(results[(aa,datasetNames[d],aapp)]) for aa in algorithms for aapp in (aproximations[:1] if aa in algorithms[:2] else aproximations)]\n",
    "    minSize=min(sizes)\n",
    "    maxSize=max(sizes)\n",
    "\n",
    "    pic.draw((-0.1,y+barHOffset),tikz.node(\"\\\\scriptsize 0\",anchor=' east'))\n",
    "    pic.draw((-0.1,y-barHOffset+datasetHeight),tikz.node(\"\\\\scriptsize \"+str(maxSize),anchor=' east'))\n",
    "\n",
    "\n",
    "\n",
    "def drawAlgorithm(pic,d,a,x,y):\n",
    "    #pic.draw((x,y),tikz.rectangle((x+algoWidth,y+datasetHeight)),color='black')\n",
    "    for ap,aprox in enumerate(aproxexp):\n",
    "        drawAprox(pic,d,a,ap,x+aproxOffset+ap*aproxWidth-0.7*min(a,2),y)\n",
    "        if a<2:\n",
    "            break\n",
    "\n",
    "    if d==0:\n",
    "        pic.draw((x+algoWidth/2-0.7*min(a,2)-(0 if a>=2 else 0.5),y-0.8),tikz.node(algorithms[a]))\n",
    "\n",
    "\n",
    "def drawAprox(pic,d,a,ap,x,y):\n",
    "    golden=DenialConstraintSet(\"goldenDCs/{}\".format(datasetNames[d]),datasetNames[d],datasets[datasetNames[d]],\"ours\")\n",
    "    golden=[frozenset(x) for x in golden.DCs]\n",
    "    res=results[(algorithms[a],datasetNames[d],aproximations[ap])]\n",
    "\n",
    "    sizes=[ len(results[(aa,datasetNames[d],aapp)]) for aa in algorithms for aapp in (aproximations[:1] if aa in algorithms[:2] else aproximations)]\n",
    "    minSize=min(sizes)\n",
    "    maxSize=max(sizes)\n",
    "    size=len(res)\n",
    "    bins=np.zeros((buckets,))\n",
    "    for dc in res:\n",
    "        if dc in golden:\n",
    "            bins[1]+=1\n",
    "        else:\n",
    "            bins[0]+=1\n",
    "    \n",
    "    bins=np.cumsum(bins)\n",
    "    bins=bins/bins[-1]\n",
    "    bins=bins*size/maxSize\n",
    "    bins= np.nan_to_num(bins,nan=0)\n",
    "    barY=0\n",
    "    \n",
    "    for i in range(len(bins)):\n",
    "        pic.definecolor(\"tmp\",'RGB',\",\".join([str(255*x) for x in colors[i]]))\n",
    "        \n",
    "        pic.draw((x+barOffset,y+barHOffset+barY*barHeight),tikz.rectangle((x+barOffset+barWidth,y+barHOffset+bins[i]*barHeight)),fill='tmp')\n",
    "        barY=bins[i]\n",
    "\n",
    "\n",
    "    if d==0  :\n",
    "        pic.draw((x+barWidth/2,y-0.3),tikz.node(\"\\\\scriptsize$\"+aproxexp[ap]+\"$\",rotate='-90'))\n",
    "\n",
    "\n",
    "def drawLegend(pic):\n",
    "    x=imgWidth/2\n",
    "    \n",
    "    legendwidth=imgWidth\n",
    "    legendHeight=legendBuckedWidth+0.4\n",
    "    y=imgHeight+0.2+ legendHeight\n",
    "\n",
    "    pic.draw((x-legendwidth/2,y),tikz.rectangle((x+legendwidth/2,y-legendHeight)),color='black')\n",
    "    #pic.draw((0.5,y-0.35),tikz.node(\"$\\\\mathbf{|\\\\varphi|:}$\",anchor='center'))\n",
    "\n",
    "    r=legendBuckedWidth\n",
    "    yy=y-0.35\n",
    "    pic.definecolor(\"tmp\",'RGB',\",\".join([str(255*c) for c in colors[0]]))\n",
    "    xx=x-3\n",
    "    pic.draw((xx-r/2,yy-r/2),tikz.rectangle((xx+r/2,yy+r/2)),fill='tmp')\n",
    "    pic.draw((xx+0.05,yy),tikz.node(\"Not a Golden DC\",anchor='west'))\n",
    "\n",
    "    pic.definecolor(\"tmp\",'RGB',\",\".join([str(255*c) for c in colors[1]]))\n",
    "    xx=x+0.5\n",
    "    pic.draw((xx-r/2,yy-r/2),tikz.rectangle((xx+r/2,yy+r/2)),fill='tmp')\n",
    "    pic.draw((xx+0.05,yy),tikz.node(\"Golden DC\",anchor='west'))\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DC precision Horizontal\n",
    "algoWidth=2\n",
    "datasetHeight=2\n",
    "\n",
    "\n",
    "imgWidth=algoWidth*len(datasetNames)\n",
    "imgHeight=datasetHeight*len(algorithms)\n",
    "\n",
    "aproxOffset=algoWidth*0.1\n",
    "aproxWidth=(algoWidth-2*aproxOffset)/len(aproxexp)\n",
    "\n",
    "barWidth=aproxWidth*0.7\n",
    "barOffset=(aproxWidth-barWidth)/2\n",
    "\n",
    "barHeight=datasetHeight*0.9\n",
    "barHOffset=(datasetHeight-barHeight)/2\n",
    "\n",
    "buckets=2\n",
    "legendBuckedWidth=0.2\n",
    "legendBucketSpace=0.4\n",
    "\n",
    "\n",
    "colors=[(0.9,0,0),(0,0.9,0)]\n",
    "def image(pic):\n",
    "    #pic.draw(tikz.rectangle((imgWidth,imgHeight)))\n",
    "\n",
    "    for a,dataset in enumerate(algorithms):\n",
    "        drawAlgorithm(pic,a,(len(algorithms)-1-a)*datasetHeight)\n",
    "    #drawLegend(pic)\n",
    "\n",
    "def drawAlgorithm(pic,a,y):\n",
    "    for d,_ in  enumerate(datasetNames):\n",
    "        drawDataset(pic,a,d,d*algoWidth,y)\n",
    "    pic.draw((imgWidth+0.3,y+datasetHeight/2),tikz.node(algorithms[a],rotate='-90'))\n",
    "    pic.draw((0,y+barHOffset),tikz.rectangle((imgWidth,y+barHOffset+barHeight)),color='black')\n",
    "\n",
    "    pic.draw((-0.1,y+barHOffset),tikz.node(\"\\\\scriptsize 0\\\\%\",anchor=' east'))\n",
    "    pic.draw((-0.1,y-barHOffset+datasetHeight),tikz.node(\"\\\\scriptsize \"+\"100\\\\%\",anchor=' east'))\n",
    "\n",
    "\n",
    "\n",
    "def drawDataset(pic,a,d,x,y):\n",
    "    #pic.draw((x,y),tikz.rectangle((x+algoWidth,y+datasetHeight)),color='black')\n",
    "    for ap,aprox in enumerate(aproxexp):\n",
    "        drawAprox(pic,d,a,ap,x+aproxOffset+ap*aproxWidth,y)\n",
    "        if a<2:\n",
    "            break\n",
    "\n",
    "    if a==len(algorithms)-1:\n",
    "        pic.draw((x+algoWidth/2,y-0.8),tikz.node(datasetNames[d]))\n",
    "\n",
    "\n",
    "def drawAprox(pic,d,a,ap,x,y):\n",
    "    golden=DenialConstraintSet(\"goldenDCs/{}\".format(datasetNames[d]),datasetNames[d],datasets[datasetNames[d]],\"ours\")\n",
    "    golden=[frozenset(x) for x in golden.DCs]\n",
    "    res=results[(algorithms[a],datasetNames[d],aproximations[ap])]\n",
    "\n",
    "    sizes=[ len(results[(aa,datasetNames[d],aapp)]) for aa in algorithms for aapp in (aproximations[:1] if aa in algorithms[:2] else aproximations)]\n",
    "    minSize=min(sizes)\n",
    "    maxSize=max(sizes)\n",
    "    size=len(res)\n",
    "    bins=np.zeros((buckets,))\n",
    "    for dc in res:\n",
    "        if dc in golden:\n",
    "            bins[1]+=1\n",
    "        else:\n",
    "            bins[0]+=1\n",
    "    \n",
    "    bins=np.cumsum(bins)\n",
    "    bins=bins/bins[-1]\n",
    "    #bins=bins*size/maxSize\n",
    "    bins= np.nan_to_num(bins,nan=0)\n",
    "    barY=0\n",
    "    \n",
    "    for i in range(len(bins)):\n",
    "        pic.definecolor(\"tmp\",'RGB',\",\".join([str(255*x) for x in colors[i]]))\n",
    "        \n",
    "        pic.draw((x+barOffset,y+barHOffset+barY*barHeight),tikz.rectangle((x+barOffset+barWidth,y+barHOffset+bins[i]*barHeight)),fill='tmp')\n",
    "        barY=bins[i]\n",
    "\n",
    "\n",
    "\n",
    "    if a==len(algorithms)-1  :\n",
    "        pic.draw((x+barWidth/2,y-0.3),tikz.node(\"\\\\scriptsize$\"+aproxexp[ap]+\"$\",rotate='-90'))\n",
    "\n",
    "\n",
    "def drawLegend(pic):\n",
    "    x=imgWidth/2\n",
    "    \n",
    "    legendwidth=buckets*legendBuckedWidth+ (buckets+1)*legendBucketSpace\n",
    "    legendHeight=legendBucketSpace*2+legendBuckedWidth+0.5\n",
    "    y=imgHeight+0.2+ legendHeight\n",
    "\n",
    "    pic.draw((x-legendwidth/2,y),tikz.rectangle((x+legendwidth/2,y-legendHeight)),color='black')\n",
    "    r=legendBuckedWidth\n",
    "    for i in range(buckets):\n",
    "        xx=x-legendwidth/2+legendBucketSpace+legendBuckedWidth/2+(legendBucketSpace+legendBuckedWidth)*i\n",
    "        yy=y-legendBucketSpace-legendBuckedWidth/2\n",
    "        pic.definecolor(\"tmp\",'RGB',\",\".join([str(255*c) for c in colors[i]]))\n",
    "        pic.draw((xx-r/2,yy-r/2),tikz.rectangle((xx+r/2,yy+r/2)),fill='tmp')\n",
    "        txt=str(i+1)\n",
    "        if i==buckets-1:\n",
    "            txt+=\"+\"\n",
    "        pic.draw((xx-r,yy-0.5),tikz.node(txt,anchor='west'))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DC independence Vertical\n",
    "algoWidth=2\n",
    "datasetHeight=2\n",
    "\n",
    "\n",
    "imgWidth=algoWidth*len(algorithms)-1.4\n",
    "imgHeight=datasetHeight*len(datasetNames)\n",
    "\n",
    "aproxOffset=algoWidth*0.1\n",
    "aproxWidth=(algoWidth-2*aproxOffset)/len(aproxexp)\n",
    "\n",
    "barWidth=aproxWidth*0.7\n",
    "barOffset=(aproxWidth-barWidth)/2\n",
    "\n",
    "barHeight=datasetHeight*0.9\n",
    "barHOffset=(datasetHeight-barHeight)/2\n",
    "\n",
    "buckets=2\n",
    "legendBuckedWidth=0.2\n",
    "legendBucketSpace=0.8\n",
    "\n",
    "colors=[(0.9,0,0),(0,0.9,0)]\n",
    "def image(pic):\n",
    "    #pic.draw(tikz.rectangle((imgWidth,imgHeight)))\n",
    "\n",
    "    for d,dataset in enumerate(datasetNames):\n",
    "        drawDataset(pic,d,d*datasetHeight)\n",
    "    drawLegend(pic)\n",
    "\n",
    "def drawDataset(pic,d,y):\n",
    "    for a,algorithm in enumerate(algorithms):\n",
    "        drawAlgorithm(pic,d,a,a*algoWidth,y)\n",
    "    pic.draw((imgWidth+0.3,y+datasetHeight/2),tikz.node(datasetNames[d],rotate='-90'))\n",
    "    pic.draw((0,y+barHOffset),tikz.rectangle((imgWidth,y+barHOffset+barHeight)),color='black')\n",
    "\n",
    "    sizes=[ len(results[(aa,datasetNames[d],aapp)]) for aa in algorithms for aapp in (aproximations[:1] if aa in algorithms[:2] else aproximations)]\n",
    "    minSize=min(sizes)\n",
    "    maxSize=max(sizes)\n",
    "\n",
    "    pic.draw((-0.1,y+barHOffset),tikz.node(\"\\\\scriptsize 0\",anchor=' east'))\n",
    "    pic.draw((-0.1,y-barHOffset+datasetHeight),tikz.node(\"\\\\scriptsize \"+str(maxSize),anchor=' east'))\n",
    "\n",
    "\n",
    "\n",
    "def drawAlgorithm(pic,d,a,x,y):\n",
    "    #pic.draw((x,y),tikz.rectangle((x+algoWidth,y+datasetHeight)),color='black')\n",
    "    for ap,aprox in enumerate(aproxexp):\n",
    "        drawAprox(pic,d,a,ap,x+aproxOffset+ap*aproxWidth-0.7*min(a,2),y)\n",
    "        if a<2:\n",
    "            break\n",
    "\n",
    "    if d==0:\n",
    "        pic.draw((x+algoWidth/2-0.7*min(a,2)-(0 if a>=2 else 0.5),y-0.8),tikz.node(algorithms[a]))\n",
    "\n",
    "\n",
    "def drawAprox(pic,d,a,ap,x,y):\n",
    "    golden=DenialConstraintSet(\"goldenDCs/{}\".format(datasetNames[d]),datasetNames[d],datasets[datasetNames[d]],\"ours\")\n",
    "    golden=[frozenset(x) for x in golden.DCs]\n",
    "    res=results[(algorithms[a],datasetNames[d],aproximations[ap])]\n",
    "\n",
    "    sizes=[ len([x for x in results[(aa,datasetNames[d],aapp)] if len(x)>1]) for aa in algorithms for aapp in (aproximations[:1] if aa in algorithms[:2] else aproximations)]\n",
    "    minSize=min(sizes)\n",
    "    maxSize=max(sizes)\n",
    "    size=len([x for x in res if len(x)>1])\n",
    "    bins=np.zeros((buckets,))\n",
    "    for dc in res:\n",
    "        if len(dc)==1:\n",
    "            continue\n",
    "        jointProb=res[dc][0]\n",
    "        indepProb=res[dc][1]\n",
    "        n=2**14\n",
    "        pval=binom.cdf(jointProb*(n*(n-1)),n*(n-1),indepProb)\n",
    "        if pval<0.05**2:\n",
    "            bins[1]+=1\n",
    "        else:\n",
    "            bins[0]+=1\n",
    "    \n",
    "    bins=np.cumsum(bins)\n",
    "    if bins[-1]>0:\n",
    "        bins=bins/bins[-1]\n",
    "        bins=bins*size/maxSize\n",
    "        bins= np.nan_to_num(bins,nan=0)\n",
    "        barY=0\n",
    "        \n",
    "        for i in range(len(bins)):\n",
    "            pic.definecolor(\"tmp\",'RGB',\",\".join([str(255*x) for x in colors[i]]))\n",
    "            \n",
    "            pic.draw((x+barOffset,y+barHOffset+barY*barHeight),tikz.rectangle((x+barOffset+barWidth,y+barHOffset+bins[i]*barHeight)),fill='tmp')\n",
    "            barY=bins[i]\n",
    "\n",
    "\n",
    "    if d==0  :\n",
    "        pic.draw((x+barWidth/2,y-0.3),tikz.node(\"\\\\scriptsize$\"+aproxexp[ap]+\"$\",rotate='-90'))\n",
    "\n",
    "\n",
    "def drawLegend(pic):\n",
    "    x=imgWidth/2\n",
    "    \n",
    "    legendwidth=imgWidth\n",
    "    legendHeight=legendBuckedWidth+0.4\n",
    "    y=imgHeight+0.2+ legendHeight\n",
    "\n",
    "    pic.draw((x-legendwidth/2,y),tikz.rectangle((x+legendwidth/2,y-legendHeight)),color='black')\n",
    "    #pic.draw((0.5,y-0.35),tikz.node(\"$\\\\mathbf{|\\\\varphi|:}$\",anchor='center'))\n",
    "\n",
    "    r=legendBuckedWidth\n",
    "    yy=y-0.35\n",
    "    pic.definecolor(\"tmp\",'RGB',\",\".join([str(255*c) for c in colors[0]]))\n",
    "    xx=0.15\n",
    "    pic.draw((xx-r/2,yy-r/2),tikz.rectangle((xx+r/2,yy+r/2)),fill='tmp')\n",
    "    pic.draw((xx+0.05,yy),tikz.node(\"Not independent predicates\",anchor='west'))\n",
    "\n",
    "    pic.definecolor(\"tmp\",'RGB',\",\".join([str(255*c) for c in colors[1]]))\n",
    "    xx=x+0.5\n",
    "    pic.draw((xx-r/2,yy-r/2),tikz.rectangle((xx+r/2,yy+r/2)),fill='tmp')\n",
    "    pic.draw((xx+0.05,yy),tikz.node(\"Independent predicates\",anchor='west'))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DC soundness Vertical\n",
    "algoWidth=2\n",
    "datasetHeight=2\n",
    "\n",
    "\n",
    "imgWidth=algoWidth*len(algorithms)-1.4\n",
    "imgHeight=datasetHeight*len(datasetNames)\n",
    "\n",
    "aproxOffset=algoWidth*0.1\n",
    "aproxWidth=(algoWidth-2*aproxOffset)/len(aproxexp)\n",
    "\n",
    "barWidth=aproxWidth*0.7\n",
    "barOffset=(aproxWidth-barWidth)/2\n",
    "\n",
    "barHeight=datasetHeight*0.9\n",
    "barHOffset=(datasetHeight-barHeight)/2\n",
    "\n",
    "buckets=2\n",
    "legendBuckedWidth=0.2\n",
    "legendBucketSpace=0.8\n",
    "\n",
    "colors=[(0.9,0,0),(0,0.9,0)]\n",
    "def image(pic):\n",
    "    #pic.draw(tikz.rectangle((imgWidth,imgHeight)))\n",
    "\n",
    "    for d,dataset in enumerate(datasetNames):\n",
    "        drawDataset(pic,d,d*datasetHeight)\n",
    "    drawLegend(pic)\n",
    "\n",
    "def drawDataset(pic,d,y):\n",
    "    for a,algorithm in enumerate(algorithms):\n",
    "        drawAlgorithm(pic,d,a,a*algoWidth,y)\n",
    "    pic.draw((imgWidth+0.3,y+datasetHeight/2),tikz.node(datasetNames[d],rotate='-90'))\n",
    "    pic.draw((0,y+barHOffset),tikz.rectangle((imgWidth,y+barHOffset+barHeight)),color='black')\n",
    "\n",
    "    sizes=[ len(results[(aa,datasetNames[d],aapp)]) for aa in algorithms for aapp in (aproximations[:1] if aa in algorithms[:2] else aproximations)]\n",
    "    minSize=min(sizes)\n",
    "    maxSize=max(sizes)\n",
    "\n",
    "    pic.draw((-0.1,y+barHOffset),tikz.node(\"\\\\scriptsize 0\",anchor=' east'))\n",
    "    pic.draw((-0.1,y-barHOffset+datasetHeight),tikz.node(\"\\\\scriptsize \"+str(maxSize),anchor=' east'))\n",
    "\n",
    "\n",
    "\n",
    "def drawAlgorithm(pic,d,a,x,y):\n",
    "    #pic.draw((x,y),tikz.rectangle((x+algoWidth,y+datasetHeight)),color='black')\n",
    "    for ap,aprox in enumerate(aproxexp):\n",
    "        drawAprox(pic,d,a,ap,x+aproxOffset+ap*aproxWidth-0.7*min(a,2),y)\n",
    "        if a<2:\n",
    "            break\n",
    "\n",
    "    if d==0:\n",
    "        pic.draw((x+algoWidth/2-0.7*min(a,2)-(0 if a>=2 else 0.5),y-0.8),tikz.node(algorithms[a]))\n",
    "\n",
    "\n",
    "def drawAprox(pic,d,a,ap,x,y):\n",
    "    golden=DenialConstraintSet(\"soundDCs/{}\".format(datasetNames[d]),datasetNames[d],datasets[datasetNames[d]],\"ours\")\n",
    "    golden=[frozenset(x) for x in golden.DCs]\n",
    "    golden=SoundDCs[datasetNames[d]]\n",
    "    res=results[(algorithms[a],datasetNames[d],aproximations[ap])]\n",
    "\n",
    "    sizes=[ len(results[(aa,datasetNames[d],aapp)]) for aa in algorithms for aapp in (aproximations[:1] if aa in algorithms[:2] else aproximations)]\n",
    "    minSize=min(sizes)\n",
    "    maxSize=max(sizes)\n",
    "    size=len(res)\n",
    "    bins=np.zeros((buckets,))\n",
    "    for dc in res:\n",
    "        if dc in golden:\n",
    "            bins[1]+=1\n",
    "        else:\n",
    "            bins[0]+=1\n",
    "    \n",
    "    bins=np.cumsum(bins)\n",
    "    bins=bins/bins[-1]\n",
    "    bins=bins*size/maxSize\n",
    "    bins= np.nan_to_num(bins,nan=0)\n",
    "    barY=0\n",
    "    \n",
    "    for i in range(len(bins)):\n",
    "        pic.definecolor(\"tmp\",'RGB',\",\".join([str(255*x) for x in colors[i]]))\n",
    "        \n",
    "        pic.draw((x+barOffset,y+barHOffset+barY*barHeight),tikz.rectangle((x+barOffset+barWidth,y+barHOffset+bins[i]*barHeight)),fill='tmp')\n",
    "        barY=bins[i]\n",
    "\n",
    "\n",
    "    if d==0  :\n",
    "        pic.draw((x+barWidth/2,y-0.3),tikz.node(\"\\\\scriptsize$\"+aproxexp[ap]+\"$\",rotate='-90'))\n",
    "\n",
    "\n",
    "def drawLegend(pic):\n",
    "    x=imgWidth/2\n",
    "    \n",
    "    legendwidth=imgWidth\n",
    "    legendHeight=legendBuckedWidth+0.4\n",
    "    y=imgHeight+0.2+ legendHeight\n",
    "\n",
    "    pic.draw((x-legendwidth/2,y),tikz.rectangle((x+legendwidth/2,y-legendHeight)),color='black')\n",
    "    #pic.draw((0.5,y-0.35),tikz.node(\"$\\\\mathbf{|\\\\varphi|:}$\",anchor='center'))\n",
    "\n",
    "    r=legendBuckedWidth\n",
    "    yy=y-0.35\n",
    "    pic.definecolor(\"tmp\",'RGB',\",\".join([str(255*c) for c in colors[0]]))\n",
    "    xx=x-3\n",
    "    pic.draw((xx-r/2,yy-r/2),tikz.rectangle((xx+r/2,yy+r/2)),fill='tmp')\n",
    "    pic.draw((xx+0.05,yy),tikz.node(\"Not Sound DC\",anchor='west'))\n",
    "\n",
    "    pic.definecolor(\"tmp\",'RGB',\",\".join([str(255*c) for c in colors[1]]))\n",
    "    xx=x+1\n",
    "    pic.draw((xx-r/2,yy-r/2),tikz.rectangle((xx+r/2,yy+r/2)),fill='tmp')\n",
    "    pic.draw((xx+0.05,yy),tikz.node(\"Sound DC\",anchor='west'))\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DC filtered precision Vertical\n",
    "algoWidth=2\n",
    "datasetHeight=2\n",
    "\n",
    "\n",
    "imgWidth=algoWidth*len(algorithms)-1.4\n",
    "imgHeight=datasetHeight*len(datasetNames)\n",
    "\n",
    "aproxOffset=algoWidth*0.1\n",
    "aproxWidth=(algoWidth-2*aproxOffset)/len(aproxexp)\n",
    "\n",
    "barWidth=aproxWidth*0.7\n",
    "barOffset=(aproxWidth-barWidth)/2\n",
    "\n",
    "barHeight=datasetHeight*0.9\n",
    "barHOffset=(datasetHeight-barHeight)/2\n",
    "\n",
    "buckets=3\n",
    "legendBuckedWidth=0.2\n",
    "legendBucketSpace=0.8\n",
    "\n",
    "colors=[(0.9,0,0),(0.9,0.9,0),(0,0.9,0)]\n",
    "def image(pic):\n",
    "    #pic.draw(tikz.rectangle((imgWidth,imgHeight)))\n",
    "\n",
    "    for d,dataset in enumerate(datasetNames):\n",
    "        drawDataset(pic,d,d*datasetHeight)\n",
    "    drawLegend(pic)\n",
    "\n",
    "def drawDataset(pic,d,y):\n",
    "    for a,algorithm in enumerate(algorithms):\n",
    "        drawAlgorithm(pic,d,a,a*algoWidth,y)\n",
    "    pic.draw((imgWidth+0.3,y+datasetHeight/2),tikz.node(datasetNames[d],rotate='-90'))\n",
    "    pic.draw((0,y+barHOffset),tikz.rectangle((imgWidth,y+barHOffset+barHeight)),color='black')\n",
    "\n",
    "    sizes=[ len(results[(aa,datasetNames[d],aapp)]) for aa in algorithms for aapp in (aproximations[:1] if aa in algorithms[:2] else aproximations)]\n",
    "    minSize=min(sizes)\n",
    "    maxSize=max(sizes)\n",
    "\n",
    "    pic.draw((-0.1,y+barHOffset),tikz.node(\"\\\\scriptsize 0\",anchor=' east'))\n",
    "    pic.draw((-0.1,y-barHOffset+datasetHeight),tikz.node(\"\\\\scriptsize \"+str(maxSize),anchor=' east'))\n",
    "\n",
    "\n",
    "\n",
    "def drawAlgorithm(pic,d,a,x,y):\n",
    "    #pic.draw((x,y),tikz.rectangle((x+algoWidth,y+datasetHeight)),color='black')\n",
    "    for ap,aprox in enumerate(aproxexp):\n",
    "        drawAprox(pic,d,a,ap,x+aproxOffset+ap*aproxWidth-0.7*min(a,2),y)\n",
    "        if a<2:\n",
    "            break\n",
    "\n",
    "    if d==0:\n",
    "        pic.draw((x+algoWidth/2-0.7*min(a,2)-(0 if a>=2 else 0.5),y-0.8),tikz.node(algorithms[a]))\n",
    "\n",
    "\n",
    "def drawAprox(pic,d,a,ap,x,y):\n",
    "    stillGood=results[(algorithms[a],datasetNames[d],'0.00')]\n",
    "\n",
    "    golden=DenialConstraintSet(\"goldenDCs/{}\".format(datasetNames[d]),datasetNames[d],datasets[datasetNames[d]],\"ours\")\n",
    "    golden=[frozenset(x) for x in golden.DCs]\n",
    "\n",
    "    res=results[(algorithms[a],datasetNames[d],aproximations[ap])]\n",
    "\n",
    "    sizes=[ len(results[(aa,datasetNames[d],aapp)]) for aa in algorithms for aapp in (aproximations[:1] if aa in algorithms[:2] else aproximations)]\n",
    "    minSize=min(sizes)\n",
    "    maxSize=max(sizes)\n",
    "    size=len(res)\n",
    "    bins=np.zeros((buckets,))\n",
    "    for dc in res:\n",
    "        if dc in golden:\n",
    "            bins[2]+=1\n",
    "        else:\n",
    "            if dc in stillGood:\n",
    "                bins[1]+=1\n",
    "            else:\n",
    "                bins[0]+=1\n",
    "    \n",
    "    bins=np.cumsum(bins)\n",
    "    bins=bins/bins[-1]\n",
    "    bins=bins*size/maxSize\n",
    "    bins= np.nan_to_num(bins,nan=0)\n",
    "    barY=0\n",
    "    \n",
    "    for i in range(len(bins)):\n",
    "        pic.definecolor(\"tmp\",'RGB',\",\".join([str(255*x) for x in colors[i]]))\n",
    "        \n",
    "        pic.draw((x+barOffset,y+barHOffset+barY*barHeight),tikz.rectangle((x+barOffset+barWidth,y+barHOffset+bins[i]*barHeight)),fill='tmp')\n",
    "        barY=bins[i]\n",
    "\n",
    "\n",
    "    if d==0  :\n",
    "        pic.draw((x+barWidth/2,y-0.3),tikz.node(\"\\\\scriptsize$\"+aproxexp[ap]+\"$\",rotate='-90'))\n",
    "\n",
    "\n",
    "def drawLegend(pic):\n",
    "    x=imgWidth/2\n",
    "    \n",
    "    legendwidth=imgWidth\n",
    "    legendHeight=legendBuckedWidth+0.4\n",
    "    y=imgHeight+0.2+ legendHeight\n",
    "\n",
    "    pic.draw((x-legendwidth/2,y),tikz.rectangle((x+legendwidth/2,y-legendHeight)),color='black')\n",
    "    #pic.draw((x,y-0.5),tikz.node(\"Is the DC Golden?\",anchor='center'))\n",
    "\n",
    "    r=legendBuckedWidth\n",
    "    yy=y-0.35\n",
    "    pic.definecolor(\"tmp\",'RGB',\",\".join([str(255*c) for c in colors[0]]))\n",
    "    xx=x-4\n",
    "    pic.draw((xx-r/2,yy-r/2),tikz.rectangle((xx+r/2,yy+r/2)),fill='tmp')\n",
    "    pic.draw((xx,yy),tikz.node(\"\\\\scriptsize Not Golden or True\",anchor='west'))\n",
    "\n",
    "    pic.definecolor(\"tmp\",'RGB',\",\".join([str(255*c) for c in colors[1]]))\n",
    "    xx=x-1.25\n",
    "    pic.draw((xx-r/2,yy-r/2),tikz.rectangle((xx+r/2,yy+r/2)),fill='tmp')\n",
    "    pic.draw((xx,yy),tikz.node(\"\\\\scriptsize Not Golden but True\",anchor='west'))\n",
    "\n",
    "    pic.definecolor(\"tmp\",'RGB',\",\".join([str(255*c) for c in colors[2]]))\n",
    "    xx=x+1.9\n",
    "    pic.draw((xx-r/2,yy-r/2),tikz.rectangle((xx+r/2,yy+r/2)),fill='tmp')\n",
    "    pic.draw((xx,yy),tikz.node(\"\\\\scriptsize Golden and True\",anchor='west'))\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pic = tikz.Picture()\n",
    "\n",
    "image(pic)\n",
    "#Use demo to directly see the image. Needs latex locally installed\n",
    "#pic.demo(dpi=100)\n",
    "#Use print to obtain tikzpicture code to compile elsewhere.\n",
    "print(pic.code())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evolution as data increases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to show the evolution of expected probabilities under independence of discovered DCs as data is increased. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allVals={}\n",
    "dataset=\"tax500k\"\n",
    "algorithm=algorithms[-1]\n",
    "aprox=aproximations[0]\n",
    "\n",
    "for nrows in range(500,20500,500):\n",
    "    \n",
    "\n",
    "    print(\"{}_{}_{}_{}\".format(algorithm,dataset,aprox,nrows))\n",
    "\n",
    "    dcs=DenialConstraintSet(\"results/{}_{}_{}_{}\".format(algorithm,dataset,aprox,nrows),dataset,datasets[dataset],algorithm)\n",
    "    golden=DenialConstraintSet(\"goldenDCs/{}\".format(dataset),dataset,datasets[dataset],\"ours\")\n",
    "    golden=[frozenset(x) for x in golden.DCs]\n",
    "    dcs.buildGraph()\n",
    "    res=[]\n",
    "    gold=[]\n",
    "    def search(b,s,node,prob=1):\n",
    "        if node[1] is not None:\n",
    "            if prob>0:\n",
    "                res.append(np.log(prob))\n",
    "            else:\n",
    "                res.append(-25)\n",
    "            if s in golden:\n",
    "                gold.append(res[-1])\n",
    "            \n",
    "        for i in range(b,len(ds.preds)):\n",
    "            if i in node[0]:\n",
    "                search(i+1,s|{i},node[0][i],prob*ds.predProbs[i])\n",
    "\n",
    "    search(0,frozenset(),dcs.root)\n",
    "    sns.scatterplot(x=nrows,y=res,s=10,alpha=0.01)\n",
    "    #sns.scatterplot(x=nrows,y=gold,s=5,alpha=1,color='black')\n",
    "\n",
    "ax=sns.lineplot(x=range(500,20500,500),y=[ np.log(1/x**2)+7 for x in range(500,20500,500)],palette='gray',linestyle='--')\n",
    "ax.set(xlabel=\"Number of tuples\",ylabel=\"$log(e(\\\\varphi))$\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
